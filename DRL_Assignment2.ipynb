{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMAPYGqBdZEn"
   },
   "source": [
    "# **Deep Reinforcement Learning Class ‚Äì Spring 2025 Assignment 2**\n",
    "\n",
    "In this assignment, you will explore multiple exploration and exploitation methods, as well as variants of Monte Carlo Tree Search (MCTS), Temporal Difference (TD) learning, n-tuple approximation, and other key reinforcement learning techniques.\n",
    "\n",
    "You will need to <font color='blue'>answer the bolded questions</font> and <font color='blue'>fill in the missing code snippets (marked by **TODO**)</font>.\n",
    "\n",
    "Make a copy of this notebook using **File > Save a copy in Drive** and edit it with your answers.\n",
    "\n",
    "**WARNING:** Do not include your name or any other personal identification information in this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTA94i9TdnXV"
   },
   "source": [
    "### **Setup**\n",
    "\n",
    "Run the following code to set up the necessary imports.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1GbXdsmPMox",
    "outputId": "76964643-2450-45b3-ab66-061be41cff19"
   },
   "source": [
    "!pip install numpy==1.23.5\n",
    "!pip install gym\n",
    "!git clone https://github.com/JKCooper2/gym-bandits.git\n",
    "!pip install /content/gym-bandits/.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:59:49.855226Z",
     "iopub.status.busy": "2025-04-09T14:59:49.855090Z",
     "iopub.status.idle": "2025-04-09T14:59:50.191753Z",
     "shell.execute_reply": "2025-04-09T14:59:50.191155Z"
    },
    "id": "EElcHk4kHXGE"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import gym_bandits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create Bandit environment\n",
    "env = gym.make(\"BanditTenArmedGaussian-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chI7t8bRYZ7r"
   },
   "source": [
    "# **Question 1: Exploring and Enhancing MCTS with Exploration Strategies and TD Learning**\n",
    "\n",
    "In this question, you will explore different **exploration strategies**, implement a **basic Monte Carlo Tree Search (MCTS)** with UCT, and enhance it using **Temporal Difference (TD) learning** with **n-tuple approximation** in the **2048 environment**.\n",
    "\n",
    "You will start by comparing multiple **exploration-exploitation** techniques in a **multi-armed bandit** environment, then move on to **MCTS with UCT**, and finally integrate **TD-learning** to improve MCTS decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "## **Steps:**\n",
    "\n",
    "### **1. Compare Exploration Strategies in Multi-Armed Bandits**\n",
    "\n",
    "- Implement and analyze **Exploration-First, Epsilon-Greedy, and UCB1** in a bandit setting.\n",
    "- Compare how these methods balance **exploration and exploitation** and evaluate their performance over multiple runs.\n",
    "- Discuss which method is most effective based on **average reward trends** and **long-term convergence behavior**.\n",
    "\n",
    "### **2. Implement Basic MCTS with UCT for 2048**\n",
    "\n",
    "- Develop a **Monte Carlo Tree Search (MCTS)** algorithm using **Upper Confidence Bound for Trees (UCT)**.\n",
    "- Implement the **Selection, Expansion, Simulation, and Backpropagation** phases.\n",
    "- Use **random rollouts** to estimate state values and guide decision-making.\n",
    "\n",
    "### **3. Enhance MCTS with TD Learning and N-Tuple Approximation**\n",
    "\n",
    "- Implement **Temporal Difference (TD) learning** with **n-tuple approximation** to estimate state values.\n",
    "- Integrate this learned value function into **MCTS**, replacing the random rollout with a **TD-based evaluation**.\n",
    "- Observe how the **learned value function improves MCTS efficiency and decision quality**.\n",
    "\n",
    "By the end of this question, you will have built a **stronger MCTS agent** that intelligently balances exploration and exploitation and leverages **value function learning** to improve search accuracy.\n",
    "\n",
    "üéØ How to Earn 15 Points?\n",
    "\n",
    "1Ô∏è‚É£ Correct Implementation of Step 1 Agents (2 points)\n",
    "/ Discussion of Three Methods (3 points)\n",
    "\n",
    "2Ô∏è‚É£ Implementation of MCTS with UCT Formula and Rollout (4 points)\n",
    "**Note: Points may be deducted for errors in formulas or function implementation.**\n",
    "\n",
    "3Ô∏è‚É£ Correct Implementation of TD Learning + Explanation (4 points)\n",
    "\n",
    "4Ô∏è‚É£ Integration of Value Approximator into MCTS + Explanation (2 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqOZfqOOIBkQ"
   },
   "source": [
    "## Explore First Agent\n",
    "\n",
    "In this cell we will dicuss an algorithm to solve bandits where,\n",
    "\n",
    "- Exploration Phase: For the first N (defined as `max_explore` in the code) steps the agent takes random actions to estimate the value of different arms.\n",
    "- Exploitation Phase: In each step after that, the agent identifies the best arm based on the information it aggregated so far.\n",
    "  Notice that the agent keeps updating its prediction even after the inital N steps.\n",
    "\n",
    "We will now implement this agent below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:59:50.193480Z",
     "iopub.status.busy": "2025-04-09T14:59:50.193273Z",
     "iopub.status.idle": "2025-04-09T14:59:50.198056Z",
     "shell.execute_reply": "2025-04-09T14:59:50.197615Z"
    },
    "id": "4_5u-mOUkoYq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class ExplorationFirstAgent:\n",
    "    def __init__(self, k=10, exploration_steps=100):\n",
    "        \"\"\"\n",
    "        Initialize an Exploration-First Agent.\n",
    "\n",
    "        Args:\n",
    "        k (int): Number of possible actions.\n",
    "        exploration_steps (int): Number of initial steps dedicated to pure exploration.\n",
    "\n",
    "        Attributes:\n",
    "        Q (np.array): Estimated value for each action.\n",
    "        N (np.array): Count of times each action has been selected.\n",
    "        t (int): Current time step.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.exploration_steps = exploration_steps\n",
    "        self.Q = np.zeros(k)\n",
    "        self.N = np.zeros(k)\n",
    "        self.t = 0\n",
    "\n",
    "    def select_action(self):\n",
    "        # TODO: For the first N steps, perform exploration; afterward, exploit\n",
    "        if self.t < self.exploration_steps:\n",
    "            action = np.random.choice(self.k)\n",
    "        else:\n",
    "            action = np.argmax(self.Q)\n",
    "\n",
    "        self.t += 1\n",
    "        return action\n",
    "\n",
    "    def update(self, action, reward):\n",
    "        # TODO: Update N, Q, and t\n",
    "        self.N[action] += 1\n",
    "        self.Q[action] += (reward - self.Q[action]) / self.N[action]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSUi5lhXIUP6"
   },
   "source": [
    "## Epsilon-greedy Agent\n",
    "\n",
    "A popular method of simultaneoulsy exploring/exploiting is $\\epsilon$-greedy exploration. The main idea is to:\n",
    "\n",
    "- Sample the (estimated) best action with probability $1-\\epsilon$\n",
    "- Perform a random action with probability $\\epsilon$\n",
    "\n",
    "By changing $\\epsilon$, we can control if the agent is conservative or exploratory. We will now implement this agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:59:50.199502Z",
     "iopub.status.busy": "2025-04-09T14:59:50.199356Z",
     "iopub.status.idle": "2025-04-09T14:59:50.203441Z",
     "shell.execute_reply": "2025-04-09T14:59:50.203004Z"
    },
    "id": "kpSOn6AKIs03"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class EpsilonGreedyAgent:\n",
    "    def __init__(self, k=10, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        Initialize an Epsilon-Greedy Agent.\n",
    "\n",
    "        Args:\n",
    "        epsilon (float): Probability of selecting a random action (exploration).\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.epsilon = epsilon\n",
    "        self.Q = np.zeros(k)\n",
    "        self.N = np.zeros(k)\n",
    "\n",
    "    def select_action(self):\n",
    "        # TODO: With probability epsilon, select a random action (exploration); otherwise, select the action with the highest Q-value (exploitation)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action = np.random.randint(self.k)\n",
    "        else:\n",
    "            action = np.argmax(self.Q)\n",
    "        return action\n",
    "\n",
    "    def update(self, action, reward):\n",
    "        # TODO: Update N, Q\n",
    "        self.N[action] += 1\n",
    "        self.Q[action] += (reward - self.Q[action]) / self.N[action]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZgr4hVCIt53"
   },
   "source": [
    "## UCB Agent\n",
    "\n",
    "Unlike **Exploration-First**, which separates exploration and exploitation into distinct phases, or **Epsilon-Greedy**, which relies on random exploration, the **UCB (Upper Confidence Bound) agent** dynamically balances exploration and exploitation based on uncertainty.\n",
    "\n",
    "The agent should be able to **intelligently decide when to explore and when to exploit**, rather than following a predefined exploration schedule or relying on random action selection.\n",
    "\n",
    "Your task is to implement the `update_Q` and `get_action` methods for a UCB agent, ensuring that it effectively leverages its confidence bounds to make optimal decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## UCB1 Formula\n",
    "\n",
    "The UCB1 algorithm selects an action `a` based on the following equation:\n",
    "\n",
    "$Q(a) + c \\cdot \\sqrt{\\frac{\\log t}{N(a)}}$\n",
    "\n",
    "where:\n",
    "\n",
    "- `Q(a)`: Estimated reward for action `a` (average of observed rewards).\n",
    "- `N(a)`: Number of times action `a` has been selected.\n",
    "- `t`: Total number of trials (time step).\n",
    "- `c`: Exploration parameter (typically set to 1.0 or tuned based on problem complexity).\n",
    "\n",
    "To implement this, you need to:\n",
    "\n",
    "1. **Ensure that each action is selected at least once** before applying the UCB formula.\n",
    "2. **Use the equation to compute UCB values** for all actions and select the one with the highest value.\n",
    "3. **Update the estimated rewards `Q(a)` after each selection** using incremental averaging:\n",
    "\n",
    "$Q(a) \\gets Q(a) + \\frac{(R - Q(a))}{N(a)}$\n",
    "\n",
    "where `R` is the reward received from selecting action `a`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:59:50.204899Z",
     "iopub.status.busy": "2025-04-09T14:59:50.204762Z",
     "iopub.status.idle": "2025-04-09T14:59:50.209187Z",
     "shell.execute_reply": "2025-04-09T14:59:50.208759Z"
    },
    "id": "ZQlds7c_JFEg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class UCB1Agent:\n",
    "    def __init__(self, k=10, c=1.0):\n",
    "        \"\"\"\n",
    "        Initialize a UCB1 Agent.\n",
    "\n",
    "        Args:\n",
    "        c (float): Exploration parameter that controls the balance between exploration and exploitation.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.c = c\n",
    "        self.Q = np.zeros(k)\n",
    "        self.N = np.zeros(k)\n",
    "        self.t = 0\n",
    "\n",
    "    def select_action(self):\n",
    "        # TODO: Implement UCB1 action selection\n",
    "        zero_indices = np.nonzero(self.N == 0)[0]\n",
    "        if len(zero_indices) > 0:\n",
    "            return np.random.choice(zero_indices)\n",
    "        else:\n",
    "            ucb_values = self.Q + self.c * np.sqrt(np.log(self.t) / self.N)\n",
    "            return np.argmax(ucb_values)\n",
    "\n",
    "    def update(self, action, reward):\n",
    "        # TODO: Update N, Q, t\n",
    "        self.N[action] += 1\n",
    "        self.Q[action] += (reward - self.Q[action]) / self.N[action]\n",
    "        self.t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqFxqhH4OU_k"
   },
   "source": [
    "## Simulation and Comparison of Exploration Strategies\n",
    "\n",
    "This experiment compares the performance of three exploration strategies: **Exploration-First, Epsilon-Greedy, and UCB1**, in a **multi-armed bandit environment**. The simulation runs each strategy for **1000** steps across **50** independent runs to evaluate their average performance.\n",
    "\n",
    "You should not modify this code‚Äîjust run it to obtain the performance comparison between the three agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:59:50.210772Z",
     "iopub.status.busy": "2025-04-09T14:59:50.210628Z",
     "iopub.status.idle": "2025-04-09T14:59:52.522105Z",
     "shell.execute_reply": "2025-04-09T14:59:52.521538Z"
    },
    "id": "l_PyLxUWJS8o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp2/b10902118/micromamba/envs/2048/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "/tmp2/b10902118/micromamba/envs/2048/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "/tmp2/b10902118/micromamba/envs/2048/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'int'>`\u001b[0m\n",
      "  logger.warn(\n",
      "/tmp2/b10902118/micromamba/envs/2048/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 200-step Avg Reward - Exploration-First: 2.281, Epsilon-Greedy: 2.108, UCB1: 2.303\n",
      "‚úÖ UCB1 performs the best in the long run!\n"
     ]
    }
   ],
   "source": [
    "def simulate(env, agent, steps=1000):\n",
    "    rewards = np.zeros(steps)\n",
    "\n",
    "    for t in range(steps):\n",
    "        action = agent.select_action()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        agent.update(action, reward)\n",
    "        rewards[t] = reward\n",
    "\n",
    "    return rewards\n",
    "\n",
    "\n",
    "num_runs = 50\n",
    "steps = 1000\n",
    "\n",
    "all_rewards_exp_first = []\n",
    "all_rewards_eg = []\n",
    "all_rewards_ucb = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    env.reset()\n",
    "    exp_first_agent = ExplorationFirstAgent(k=10, exploration_steps=100)\n",
    "    rewards_exp_first = simulate(env, exp_first_agent, steps)\n",
    "    all_rewards_exp_first.append(rewards_exp_first)\n",
    "\n",
    "    env.reset()\n",
    "    epsilon_greedy_agent = EpsilonGreedyAgent(k=10, epsilon=0.1)\n",
    "    rewards_eg = simulate(env, epsilon_greedy_agent, steps)\n",
    "    all_rewards_eg.append(rewards_eg)\n",
    "\n",
    "    env.reset()\n",
    "    ucb_agent = UCB1Agent(k=10, c=1.0)\n",
    "    rewards_ucb = simulate(env, ucb_agent, steps)\n",
    "    all_rewards_ucb.append(rewards_ucb)\n",
    "\n",
    "avg_rewards_exp_first = np.mean(all_rewards_exp_first, axis=0)\n",
    "avg_rewards_eg = np.mean(all_rewards_eg, axis=0)\n",
    "avg_rewards_ucb = np.mean(all_rewards_ucb, axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(avg_rewards_exp_first, label=\"Exploration-First\", color=\"green\")\n",
    "plt.plot(avg_rewards_eg, label=\"Epsilon-Greedy\", color=\"blue\")\n",
    "plt.plot(avg_rewards_ucb, label=\"UCB1\", color=\"orange\")\n",
    "\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Average Reward\")\n",
    "plt.title(\n",
    "    \"Comparison of Exploration-First, Epsilon-Greedy, and UCB1 (Averaged Over 50 Runs)\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "final_avg_exp_first = np.mean(avg_rewards_exp_first[-200:])\n",
    "final_avg_eg = np.mean(avg_rewards_eg[-200:])\n",
    "final_avg_ucb = np.mean(avg_rewards_ucb[-200:])\n",
    "\n",
    "print(\n",
    "    f\"Final 200-step Avg Reward - Exploration-First: {final_avg_exp_first:.3f}, Epsilon-Greedy: {final_avg_eg:.3f}, UCB1: {final_avg_ucb:.3f}\"\n",
    ")\n",
    "\n",
    "if final_avg_exp_first > final_avg_eg and final_avg_exp_first > final_avg_ucb:\n",
    "    print(\"‚úÖ Exploration-First performs the best in the long run!\")\n",
    "elif final_avg_eg > final_avg_exp_first and final_avg_eg > final_avg_ucb:\n",
    "    print(\"‚úÖ Epsilon-Greedy performs the best in the long run!\")\n",
    "else:\n",
    "    print(\"‚úÖ UCB1 performs the best in the long run!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jsrh3mUETPcC"
   },
   "source": [
    "**Question (3pts):**\n",
    "\n",
    "Based on the plotted results, which exploration strategy (**Exploration-First, Epsilon-Greedy, or UCB1**) performed the best? Why?\n",
    "\n",
    "Analyze the reasons behind this outcome. How do different strategies balance exploration and exploitation, leading to these results?  \n",
    "Provide an explanation based on the observed trends, identifying which strategy was the most effective in this environment and comparing its advantages and limitations to the others.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- Exploration-First performs bad in the beginning due to pure random action. It focuses on current best actions in the late stage, but current best can be sub-optimal.\n",
    "\n",
    "- Epsilon-Greedy's 0.1 probability for random act can be harmful in the late stage.\n",
    "\n",
    "- UCB1 ensures all actions are well explored and the bound approaches pure Q-value (pure exploit).\n",
    "\n",
    "UCB1 performs the best\n",
    "\n",
    "Limitation: UCB1 must have all actions tried once. It will struggle with large action space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYrvdcjPsKrW"
   },
   "source": [
    "## Applying Exploration Strategies to 2048: MCTS and TD-Learning\n",
    "\n",
    "Now that you have explored different **exploration strategies** and gained an understanding of how they balance exploration and exploitation, it‚Äôs time to apply these concepts to a more complex decision-making problem: **the game of 2048**.\n",
    "\n",
    "In this section, you will implement **Monte Carlo Tree Search (MCTS) with UCT** and enhance it using **Temporal Difference (TD) learning with n-tuple approximation**. Before diving into the implementation, take a moment to develop an intuition for the game itself. You can try playing 2048 at this [link](https://play2048.co/) to familiarize yourself with its mechanics.\n",
    "\n",
    "You **do not** need to modify the provided 2048 environment code. However, if you find that certain adjustments could improve your training process, feel free to make changes. Just ensure that your modifications **do not alter the fundamental behavior of the environment**.\n",
    "\n",
    "**_Note: While some versions of 2048 terminate as soon as the 2048 tile is reached, our environment will continue running until no legal moves remain._**\n",
    "\n",
    "Now, let‚Äôs move forward with implementing **MCTS and TD-learning**, leveraging what we've learned about exploration and structured search to improve decision-making in 2048!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:59:52.523915Z",
     "iopub.status.busy": "2025-04-09T14:59:52.523766Z",
     "iopub.status.idle": "2025-04-09T14:59:52.547483Z",
     "shell.execute_reply": "2025-04-09T14:59:52.546984Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "COLOR_MAP = {\n",
    "    0: \"#cdc1b4\",\n",
    "    2: \"#eee4da\",\n",
    "    4: \"#ede0c8\",\n",
    "    8: \"#f2b179\",\n",
    "    16: \"#f59563\",\n",
    "    32: \"#f67c5f\",\n",
    "    64: \"#f65e3b\",\n",
    "    128: \"#edcf72\",\n",
    "    256: \"#edcc61\",\n",
    "    512: \"#edc850\",\n",
    "    1024: \"#edc53f\",\n",
    "    2048: \"#edc22e\",\n",
    "    4096: \"#3c3a32\",\n",
    "    8192: \"#3c3a32\",\n",
    "    16384: \"#3c3a32\",\n",
    "    32768: \"#3c3a32\",\n",
    "}\n",
    "TEXT_COLOR = {\n",
    "    2: \"#776e65\",\n",
    "    4: \"#776e65\",\n",
    "    8: \"#f9f6f2\",\n",
    "    16: \"#f9f6f2\",\n",
    "    32: \"#f9f6f2\",\n",
    "    64: \"#f9f6f2\",\n",
    "    128: \"#f9f6f2\",\n",
    "    256: \"#f9f6f2\",\n",
    "    512: \"#f9f6f2\",\n",
    "    1024: \"#f9f6f2\",\n",
    "    2048: \"#f9f6f2\",\n",
    "    4096: \"#f9f6f2\",\n",
    "}\n",
    "\n",
    "\n",
    "class Game2048Env(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(Game2048Env, self).__init__()\n",
    "\n",
    "        self.size = 4\n",
    "        self.board = np.zeros((self.size, self.size), dtype=int)\n",
    "        self.score = 0\n",
    "\n",
    "        # Action space: 0: up, 1: down, 2: left, 3: right\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n",
    "\n",
    "        self.last_move_valid = True\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.size, self.size), dtype=int)\n",
    "        self.score = 0\n",
    "        self.add_random_tile()\n",
    "        self.add_random_tile()\n",
    "        return self.board\n",
    "\n",
    "    def add_random_tile(self):\n",
    "        empty_cells = list(zip(*np.where(self.board == 0)))\n",
    "        if empty_cells:\n",
    "            x, y = random.choice(empty_cells)\n",
    "            self.board[x, y] = 2 if random.random() < 0.9 else 4\n",
    "\n",
    "    def compress(self, row):\n",
    "        new_row = row[row != 0]\n",
    "        new_row = np.pad(new_row, (0, self.size - len(new_row)), mode=\"constant\")\n",
    "        return new_row\n",
    "\n",
    "    def merge(self, row):\n",
    "        for i in range(len(row) - 1):\n",
    "            if row[i] == row[i + 1] and row[i] != 0:\n",
    "                row[i] *= 2\n",
    "                row[i + 1] = 0\n",
    "                self.score += row[i]\n",
    "        return row\n",
    "\n",
    "    def move_left(self):\n",
    "        moved = False\n",
    "        for i in range(self.size):\n",
    "            original_row = self.board[i].copy()\n",
    "            new_row = self.compress(self.board[i])\n",
    "            new_row = self.merge(new_row)\n",
    "            new_row = self.compress(new_row)\n",
    "            self.board[i] = new_row\n",
    "            if not np.array_equal(original_row, self.board[i]):\n",
    "                moved = True\n",
    "        return moved\n",
    "\n",
    "    def move_right(self):\n",
    "        moved = False\n",
    "        for i in range(self.size):\n",
    "            original_row = self.board[i].copy()\n",
    "            reversed_row = self.board[i][::-1]\n",
    "            reversed_row = self.compress(reversed_row)\n",
    "            reversed_row = self.merge(reversed_row)\n",
    "            reversed_row = self.compress(reversed_row)\n",
    "            self.board[i] = reversed_row[::-1]\n",
    "            if not np.array_equal(original_row, self.board[i]):\n",
    "                moved = True\n",
    "        return moved\n",
    "\n",
    "    def move_up(self):\n",
    "        moved = False\n",
    "        for j in range(self.size):\n",
    "            original_col = self.board[:, j].copy()\n",
    "            col = self.compress(self.board[:, j])\n",
    "            col = self.merge(col)\n",
    "            col = self.compress(col)\n",
    "            self.board[:, j] = col\n",
    "            if not np.array_equal(original_col, self.board[:, j]):\n",
    "                moved = True\n",
    "        return moved\n",
    "\n",
    "    def move_down(self):\n",
    "        moved = False\n",
    "        for j in range(self.size):\n",
    "            original_col = self.board[:, j].copy()\n",
    "            reversed_col = self.board[:, j][::-1]\n",
    "            reversed_col = self.compress(reversed_col)\n",
    "            reversed_col = self.merge(reversed_col)\n",
    "            reversed_col = self.compress(reversed_col)\n",
    "            self.board[:, j] = reversed_col[::-1]\n",
    "            if not np.array_equal(original_col, self.board[:, j]):\n",
    "                moved = True\n",
    "        return moved\n",
    "\n",
    "    def is_game_over(self):\n",
    "        if np.any(self.board == 0):\n",
    "            return False\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size - 1):\n",
    "                if self.board[i, j] == self.board[i, j + 1]:\n",
    "                    return False\n",
    "        for j in range(self.size):\n",
    "            for i in range(self.size - 1):\n",
    "                if self.board[i, j] == self.board[i + 1, j]:\n",
    "                    return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action), \"Invalid action\"\n",
    "\n",
    "        if action == 0:\n",
    "            moved = self.move_up()\n",
    "        elif action == 1:\n",
    "            moved = self.move_down()\n",
    "        elif action == 2:\n",
    "            moved = self.move_left()\n",
    "        elif action == 3:\n",
    "            moved = self.move_right()\n",
    "        else:\n",
    "            moved = False\n",
    "\n",
    "        self.last_move_valid = moved\n",
    "\n",
    "        afterstate = self.board.copy()\n",
    "        if moved:\n",
    "            self.add_random_tile()\n",
    "\n",
    "        done = self.is_game_over()\n",
    "\n",
    "        return self.board.copy(), self.score, done, afterstate\n",
    "\n",
    "    def render(self, mode=\"human\", action=None):\n",
    "        return\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlim(-0.5, self.size - 0.5)\n",
    "        ax.set_ylim(-0.5, self.size - 0.5)\n",
    "\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                value = self.board[i, j]\n",
    "                color = COLOR_MAP.get(value, \"#3c3a32\")\n",
    "                text_color = TEXT_COLOR.get(value, \"white\")\n",
    "                rect = plt.Rectangle(\n",
    "                    (j - 0.5, i - 0.5), 1, 1, facecolor=color, edgecolor=\"black\"\n",
    "                )\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "                if value != 0:\n",
    "                    ax.text(\n",
    "                        j,\n",
    "                        i,\n",
    "                        str(value),\n",
    "                        ha=\"center\",\n",
    "                        va=\"center\",\n",
    "                        fontsize=16,\n",
    "                        fontweight=\"bold\",\n",
    "                        color=text_color,\n",
    "                    )\n",
    "        title = f\"score: {self.score}\"\n",
    "        if action is not None:\n",
    "            title += f\" | action: {self.actions[action]}\"\n",
    "        plt.title(title)\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()\n",
    "\n",
    "    def simulate_row_move(self, row):\n",
    "        new_row = row[row != 0]\n",
    "        new_row = np.pad(new_row, (0, self.size - len(new_row)), mode=\"constant\")\n",
    "        for i in range(len(new_row) - 1):\n",
    "            if new_row[i] == new_row[i + 1] and new_row[i] != 0:\n",
    "                new_row[i] *= 2\n",
    "                new_row[i + 1] = 0\n",
    "        new_row = new_row[new_row != 0]\n",
    "        new_row = np.pad(new_row, (0, self.size - len(new_row)), mode=\"constant\")\n",
    "        return new_row\n",
    "\n",
    "    def is_move_legal(self, action):\n",
    "        temp_board = self.board.copy()\n",
    "\n",
    "        if action == 0:  # Move up\n",
    "            for j in range(self.size):\n",
    "                col = temp_board[:, j]\n",
    "                new_col = self.simulate_row_move(col)\n",
    "                temp_board[:, j] = new_col\n",
    "        elif action == 1:  # Move down\n",
    "            for j in range(self.size):\n",
    "                col = temp_board[:, j][::-1]\n",
    "                new_col = self.simulate_row_move(col)\n",
    "                temp_board[:, j] = new_col[::-1]\n",
    "        elif action == 2:  # Move left\n",
    "            for i in range(self.size):\n",
    "                row = temp_board[i]\n",
    "                temp_board[i] = self.simulate_row_move(row)\n",
    "        elif action == 3:  # Move right\n",
    "            for i in range(self.size):\n",
    "                row = temp_board[i][::-1]\n",
    "                new_row = self.simulate_row_move(row)\n",
    "                temp_board[i] = new_row[::-1]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action\")\n",
    "        return not np.array_equal(self.board, temp_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from env import Game2048Env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MNbRLLv1s6T"
   },
   "source": [
    "This snippet initializes and runs a random agent in the 2048 environment, selecting moves randomly from the set of legal actions.\n",
    "\n",
    "You can execute this code to observe the gameplay and get an estimate of the score when playing randomly. This will serve as a baseline to compare against more advanced techniques such as MCTS and TD-learning, helping you evaluate their effectiveness in improving performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:59:52.548979Z",
     "iopub.status.busy": "2025-04-09T14:59:52.548840Z",
     "iopub.status.idle": "2025-04-09T15:00:02.620497Z",
     "shell.execute_reply": "2025-04-09T15:00:02.619865Z"
    },
    "id": "UbWdkJMPHCMg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score over 100 games: 1064.28\n"
     ]
    }
   ],
   "source": [
    "env = Game2048Env()\n",
    "\n",
    "scores = []\n",
    "for _ in range(100):\n",
    "    state = env.reset()\n",
    "    # env.render()\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        legal_moves = [action for action in [0, 1, 2, 3] if env.is_move_legal(action)]\n",
    "        action = random.choice(legal_moves)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "    scores.append(env.score)\n",
    "    # env.render(action=action)\n",
    "print(\"Average score over 100 games:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJ6oTIYZ2r_K"
   },
   "source": [
    "## Introduction to MCTS with UCT and Rollout\n",
    "\n",
    "In this section, we will implement Monte Carlo Tree Search (MCTS) using only the Upper Confidence Bound for Trees (UCT) formula and rollout, without any policy or value approximation.\n",
    "\n",
    "MCTS consists of four main steps:\n",
    "\n",
    "1. Selection ‚Äì Traverse the tree by selecting child nodes based on the UCT formula, balancing exploration and exploitation.\n",
    "2. Expansion ‚Äì If a node has untried actions, expand the tree by adding a new child node.\n",
    "3. Rollout (Simulation) ‚Äì Perform a random simulation from the newly expanded node to estimate its value.\n",
    "4. Backpropagation ‚Äì Update the node's statistics by propagating the simulation result back up the tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T15:00:02.622500Z",
     "iopub.status.busy": "2025-04-09T15:00:02.622338Z",
     "iopub.status.idle": "2025-04-09T15:00:02.633573Z",
     "shell.execute_reply": "2025-04-09T15:00:02.633074Z"
    },
    "id": "UtIoDEG1gUzL"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# UCT Node for MCTS\n",
    "class UCTNode:\n",
    "    def __init__(self, state, score, parent=None, action=None):\n",
    "        \"\"\"\n",
    "        state: current board state (numpy array)\n",
    "        score: cumulative score at this node (2048's?)\n",
    "        parent: parent node (None for root)\n",
    "        action: action taken from parent to reach this node\n",
    "        \"\"\"\n",
    "        self.state = state\n",
    "        self.score = score\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.children = {}\n",
    "        self.visits = 0\n",
    "        self.total_reward = 0.0\n",
    "        self.untried_actions = [\n",
    "            a for a in range(4) if env.is_move_legal(a)\n",
    "        ]  # already checked, including gameover\n",
    "\n",
    "    def fully_expanded(self):\n",
    "        # A node is fully expanded if no legal actions remain untried.\n",
    "        return len(self.untried_actions) == 0\n",
    "\n",
    "\n",
    "class UCTMCTS:\n",
    "    def __init__(\n",
    "        self, env, iterations=500, exploration_constant=1.41, rollout_depth=10\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.iterations = iterations\n",
    "        self.c = exploration_constant  # Balances exploration and exploitation\n",
    "        self.rollout_depth = rollout_depth\n",
    "\n",
    "    def create_env_from_state(self, state, score):\n",
    "        \"\"\"\n",
    "        Creates a deep copy of the environment with a given board state and score.\n",
    "        \"\"\"\n",
    "        # new_env = Game2048Env()\n",
    "        # new_env.reset(state, score)\n",
    "        # return new_env\n",
    "        new_env = copy.deepcopy(self.env)\n",
    "        new_env.board = state.copy()\n",
    "        new_env.score = score\n",
    "        return new_env\n",
    "\n",
    "    def select_child(self, node):\n",
    "        # TODO: Use the UCT formula: Q + c * sqrt(log(parent_visits)/child_visits) to select the child\n",
    "        if len(node.untried_actions) != 0:\n",
    "            return node.children[node.untried_actions[0]]\n",
    "        else:\n",
    "            uct_max = -np.inf\n",
    "            child_max = None\n",
    "            for action, child in node.children.items():\n",
    "                uct_value = child.total_reward / child.visits + self.c * np.sqrt(\n",
    "                    np.log(node.visits) / child.visits\n",
    "                )\n",
    "                if uct_value > uct_max:\n",
    "                    uct_max = uct_value\n",
    "                    child_max = child\n",
    "\n",
    "            return child_max\n",
    "\n",
    "    def rollout(self, sim_env, depth):\n",
    "        # TODO: Perform a random rollout from the current state up to the specified depth.\n",
    "        score = sim_env.score\n",
    "        while not sim_env.is_game_over() and depth > 0:\n",
    "            legal_moves = [a for a in range(4) if sim_env.is_move_legal(a)]\n",
    "            if len(legal_moves) == 0:\n",
    "                break\n",
    "            action = random.choice(legal_moves)\n",
    "            state, score, done, _ = sim_env.step(action)\n",
    "            depth -= 1\n",
    "\n",
    "        return score\n",
    "\n",
    "    def backpropagate(self, node, reward):\n",
    "        # TODO: Propagate the reward up the tree, updating visit counts and total rewards.\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.total_reward += reward\n",
    "            node = node.parent\n",
    "\n",
    "    def run_simulation(self, root):\n",
    "        node = root\n",
    "        # results in avg 4337.2\n",
    "        # sim_env = self.create_env_from_state(node.state, node.score)\n",
    "        # TODO: Selection: Traverse the tree until reaching a non-fully expanded node.\n",
    "        while node.fully_expanded():\n",
    "            child = self.select_child(node)\n",
    "            if child is None:\n",
    "                break\n",
    "            node = child\n",
    "\n",
    "        # make env here should be correct\n",
    "        sim_env = self.create_env_from_state(node.state, node.score)\n",
    "\n",
    "        # TODO: Expansion: if the node has untried actions, expand one.\n",
    "        if len(node.untried_actions) != 0:\n",
    "            action = random.choice(node.untried_actions)\n",
    "            node.untried_actions.remove(action)\n",
    "            state, score, done, _ = sim_env.step(action)\n",
    "            expanded_node = UCTNode(state, score)\n",
    "            node.children[action] = expanded_node\n",
    "            expanded_node.parent = node\n",
    "            node = expanded_node\n",
    "\n",
    "        # Rollout: Simulate a random game from the expanded node.\n",
    "        rollout_reward = self.rollout(sim_env, self.rollout_depth)\n",
    "        # Backpropagation: Update the tree with the rollout reward.\n",
    "        self.backpropagate(node, rollout_reward)\n",
    "\n",
    "    def best_action_distribution(self, root):\n",
    "        \"\"\"\n",
    "        Computes the visit count distribution for each action at the root node.\n",
    "        \"\"\"\n",
    "        total_visits = sum(child.visits for child in root.children.values())\n",
    "        distribution = np.zeros(4)\n",
    "        best_visits = -1\n",
    "        best_action = None\n",
    "        for action, child in root.children.items():\n",
    "            distribution[action] = (\n",
    "                child.visits / total_visits if total_visits > 0 else 0\n",
    "            )\n",
    "            if child.visits > best_visits:\n",
    "                best_visits = child.visits\n",
    "                best_action = action\n",
    "        return best_action, distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-1rLwJX4sw0"
   },
   "source": [
    "### Playing 2048 Using MCTS\n",
    "\n",
    "This section runs a 2048 game using Monte Carlo Tree Search (MCTS), selecting moves based on Upper Confidence Bound for Trees (UCT).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T15:00:02.635045Z",
     "iopub.status.busy": "2025-04-09T15:00:02.634905Z",
     "iopub.status.idle": "2025-04-09T15:02:50.012282Z",
     "shell.execute_reply": "2025-04-09T15:02:50.011676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.88 0.02 0.08]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.04 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.06 0.02 0.9  0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.92 0.   0.08]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.98 0.   0.   0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.12 0.02 0.84 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.08 0.88 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.08 0.   0.9  0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.   0.98]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.94 0.04 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.08 0.9 ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.86 0.1 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.9  0.04 0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.06 0.22 0.7  0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.08 0.86 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.12 0.7  0.16]\n",
      "MCTS selected action: 0 with visit distribution: [0.74 0.22 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.08 0.88 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.02 0.04 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.04 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.06 0.02 0.04 0.88]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.98 0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.88 0.08 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.04 0.94 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.04 0.92]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.54 0.02 0.02 0.42]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.88 0.08]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.06 0.   0.92]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.84 0.12 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "MCTS selected action: 0 with visit distribution: [0.86 0.1  0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.98 0.   0.   0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.06 0.92]\n",
      "MCTS selected action: 1 with visit distribution: [0.08 0.88 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.06 0.02 0.9  0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.94 0.   0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.04 0.92]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.82 0.02 0.12 0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.84 0.04 0.02 0.1 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.08 0.02 0.88]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.1  0.02 0.84]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.7  0.02 0.02 0.26]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.84 0.04 0.06 0.06]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.08 0.02 0.02 0.88]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.9  0.06]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.88 0.06 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.08 0.02 0.02 0.88]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.   0.04 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.02 0.02 0.06]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.06 0.9  0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.08 0.   0.9  0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.98 0.   0.   0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.94 0.   0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.88 0.08 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.08 0.88 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.86 0.02 0.1  0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.26 0.04 0.6  0.1 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.84 0.12 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.   0.98]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.06 0.9  0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.16 0.02 0.8 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.02 0.06 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.   0.04]\n",
      "MCTS selected action: 0 with visit distribution: [0.84 0.06 0.02 0.08]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "MCTS selected action: 1 with visit distribution: [0.1  0.84 0.04 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.08 0.86 0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.04 0.06 0.88]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.   0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.9  0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.   0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.04 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.06 0.9 ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.28 0.02 0.06 0.64]\n",
      "MCTS selected action: 0 with visit distribution: [0.72 0.02 0.2  0.06]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.06 0.92]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.94 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.94 0.04]\n",
      "MCTS selected action: 0 with visit distribution: [0.84 0.08 0.06 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.88 0.02 0.02 0.08]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.04 0.04 0.9 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.04 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.02 0.02 0.06]\n",
      "MCTS selected action: 0 with visit distribution: [0.76 0.02 0.04 0.18]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.02 0.88 0.06]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.92 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.04 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.06 0.   0.02 0.92]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.06 0.02 0.92]\n",
      "MCTS selected action: 2 with visit distribution: [0.1  0.02 0.86 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "MCTS selected action: 1 with visit distribution: [0.06 0.9  0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.92 0.06]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.04 0.9  0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.88 0.08 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "MCTS selected action: 1 with visit distribution: [0.18 0.68 0.1  0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.02 0.08 0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.86 0.04 0.1 ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.   0.06]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.88 0.02 0.02 0.08]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.06 0.02 0.08 0.84]\n",
      "MCTS selected action: 3 with visit distribution: [0.06 0.06 0.04 0.84]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.04 0.02 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.04 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.08 0.88]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.94 0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.02 0.04 0.9 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.14 0.02 0.02 0.82]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.9  0.08 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.88 0.08]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.06 0.9  0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.1  0.02 0.84]\n",
      "MCTS selected action: 2 with visit distribution: [0.06 0.   0.94 0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.98 0.   0.   0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.92 0.06]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.9  0.08 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.08 0.9 ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.16 0.8 ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.88 0.08]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.04 0.92]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.08 0.88 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.06 0.9  0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.86 0.02 0.08]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.04 0.94]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.   0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.04 0.92 0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.02 0.04 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "MCTS selected action: 0 with visit distribution: [0.84 0.1  0.04 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.86 0.02 0.12 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "MCTS selected action: 3 with visit distribution: [0.1  0.02 0.02 0.86]\n",
      "MCTS selected action: 0 with visit distribution: [0.84 0.12 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.08 0.9 ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.04 0.92]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.9  0.02 0.06]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.9  0.06]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.98 0.   0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.   0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.06 0.9 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.08 0.02 0.02 0.88]\n",
      "MCTS selected action: 1 with visit distribution: [0.1  0.86 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.86 0.1  0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.98 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.86 0.04 0.02 0.08]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.9  0.   0.08]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.   0.02 0.06]\n",
      "MCTS selected action: 3 with visit distribution: [0.24 0.02 0.2  0.54]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.   0.98]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.98 0.02 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.98 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.12 0.84 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.   0.98]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.98 0.   0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.   0.04 0.96]\n",
      "MCTS selected action: 3 with visit distribution: [0.06 0.06 0.06 0.82]\n",
      "MCTS selected action: 1 with visit distribution: [0.08 0.82 0.02 0.08]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.04 0.02 0.9 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.   0.04 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.86 0.02 0.08 0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.88 0.06 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.06 0.86 0.02 0.06]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.9 0.  0.1 0. ]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.   0.96 0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.94 0.02 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "MCTS selected action: 2 with visit distribution: [0.06 0.02 0.9  0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.12 0.86 0.   0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.92 0.04 0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.98 0.   0.02 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.76 0.04 0.18 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.84 0.14 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.   0.02 0.98]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.06 0.04 0.8  0.1 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.16 0.02 0.82]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.94 0.02 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.1  0.84 0.06]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.06 0.04 0.9 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.88 0.04 0.06 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.   0.06]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.   0.04 0.06]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.04 0.92]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.92 0.06]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.04 0.02 0.9 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.06 0.9  0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.08 0.88 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.06 0.   0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.08 0.84 0.02 0.06]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.08 0.   0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.   0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.9  0.06]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.9  0.02 0.06]\n",
      "MCTS selected action: 3 with visit distribution: [0.12 0.02 0.02 0.84]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.94 0.   0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.1  0.   0.86 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.04 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.1  0.14 0.72]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.06 0.02 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.16 0.8  0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "MCTS selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.   0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.06 0.92 0.   0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.   0.98]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.08 0.   0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.04 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.   0.96 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.88 0.   0.1 ]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.92 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.26 0.   0.7  0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.06 0.92 0.   0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.   0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.04 0.88 0.08]\n",
      "MCTS selected action: 0 with visit distribution: [0.82 0.06 0.06 0.06]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.8  0.1  0.08]\n",
      "MCTS selected action: 0 with visit distribution: [0.82 0.   0.12 0.06]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.88 0.06]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.04 0.04 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.06 0.02 0.92]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.9  0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.06 0.   0.02 0.92]\n",
      "MCTS selected action: 1 with visit distribution: [0.16 0.78 0.06 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.08 0.9  0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.   0.02 0.04]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.02 0.04 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.8  0.02 0.18]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.04 0.04 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.   0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.1  0.86]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.06 0.02 0.9  0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.88 0.02 0.02 0.08]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.04 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.8  0.04 0.1  0.06]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.02 0.02 0.06]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.88 0.04 0.06]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.22 0.74 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.   0.98]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.02 0.02 0.06]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.86 0.08 0.02 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.14 0.82 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.08 0.86 0.04 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.04 0.   0.08 0.88]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.06 0.14 0.8 ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.   0.06]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.04 0.   0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.06 0.   0.   0.94]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.16 0.76 0.06 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.9  0.02 0.06]\n",
      "MCTS selected action: 0 with visit distribution: [0.84 0.08 0.08 0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.86 0.02 0.1  0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.02 0.04 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.12 0.7  0.14 0.04]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.02 0.   0.08]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.02 0.04 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.9  0.06]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.06 0.9 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.92 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.92 0.06]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.  0.1 0.1 0.8]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.04 0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.84 0.   0.16 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.78 0.08 0.02 0.12]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.34 0.6  0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.08 0.04 0.02 0.86]\n",
      "MCTS selected action: 1 with visit distribution: [0.08 0.88 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.9  0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.92 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.08 0.9 ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.04 0.92]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.06 0.02 0.9  0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.02 0.02 0.06]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.04 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.98 0.   0.02 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.04 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.02 0.06 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.12 0.82 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.88 0.02 0.06 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.1  0.04 0.84]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.9  0.02 0.06]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.04 0.9  0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.88 0.08 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.86 0.02 0.1  0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.86 0.02 0.02 0.1 ]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.02 0.04 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.98 0.02 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.02 0.9  0.04]\n",
      "MCTS selected action: 0 with visit distribution: [0.88 0.02 0.   0.1 ]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.08 0.   0.02 0.9 ]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.   0.04 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.04 0.9  0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.94 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 3 with visit distribution: [0.12 0.12 0.06 0.7 ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.06 0.9  0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.92 0.   0.04 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.9  0.06 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.92 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.06 0.   0.92 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.84 0.   0.   0.16]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.14 0.8  0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.18 0.   0.8  0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.08 0.02 0.02 0.88]\n",
      "MCTS selected action: 0 with visit distribution: [0.88 0.06 0.06 0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.88 0.02 0.   0.1 ]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.   0.94 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.14 0.02 0.04 0.8 ]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.94 0.   0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.86 0.1  0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.1  0.   0.88 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.   0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.9  0.02 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.98 0.   0.   0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.9  0.06 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.08 0.1  0.8  0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.1  0.86 0.02 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.9  0.08 0.   0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.06 0.9  0.02 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.   0.02 0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.94 0.04 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "MCTS selected action: 2 with visit distribution: [0.12 0.   0.88 0.  ]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 3 with visit distribution: [0.1  0.06 0.08 0.76]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.06 0.   0.92 0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.16 0.84 0.   0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.04 0.14 0.78 0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.   0.02 0.98]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.98 0.   0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "MCTS selected action: 1 with visit distribution: [0.04 0.82 0.02 0.12]\n",
      "MCTS selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "MCTS selected action: 2 with visit distribution: [0.02 0.16 0.7  0.12]\n",
      "MCTS selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "MCTS selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "MCTS selected action: 2 with visit distribution: [0.   0.02 0.98 0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.02 0.98 0.   0.  ]\n",
      "MCTS selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "MCTS selected action: 1 with visit distribution: [0.   0.96 0.   0.04]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.   0.02 0.98]\n",
      "MCTS selected action: 3 with visit distribution: [0.   0.   0.02 0.98]\n",
      "MCTS selected action: 2 with visit distribution: [0.  0.  0.5 0.5]\n",
      "MCTS selected action: 0 with visit distribution: [0.5 0.5 0.  0. ]\n",
      "Game over, final score: 12364\n"
     ]
    }
   ],
   "source": [
    "env = Game2048Env()\n",
    "state = env.reset()\n",
    "env.render()\n",
    "\n",
    "# Instantiate the MCTS object with specified parameters\n",
    "# You can adjust these parameters to experiment with different strategies\n",
    "uct_mcts = UCTMCTS(env, iterations=50, exploration_constant=1.41, rollout_depth=10)\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    root = UCTNode(state, env.score)  # Initialize the root node for MCTS\n",
    "\n",
    "    # Run multiple simulations to construct and refine the search tree\n",
    "    for _ in range(uct_mcts.iterations):\n",
    "        uct_mcts.run_simulation(root)\n",
    "\n",
    "    # Select the best action based on the visit distribution of the root's children\n",
    "    best_action, visit_distribution = uct_mcts.best_action_distribution(root)\n",
    "    print(\n",
    "        \"MCTS selected action:\",\n",
    "        best_action,\n",
    "        \"with visit distribution:\",\n",
    "        visit_distribution,\n",
    "    )\n",
    "\n",
    "    state, reward, done, _ = env.step(best_action)\n",
    "    env.render(action=best_action)  # Display the updated game state\n",
    "\n",
    "\n",
    "print(\"Game over, final score:\", env.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T36nediRhFx9"
   },
   "source": [
    "\"\"\"\n",
    "Average score over 10 games: 7317.2\n",
    "Game over, final score: 7428\n",
    "\"\"\"\n",
    "```python\n",
    "env = Game2048Env()\n",
    "state = env.reset()\n",
    "env.render()\n",
    "\n",
    "# Instantiate the MCTS object with specified parameters\n",
    "# You can adjust these parameters to experiment with different strategies\n",
    "uct_mcts = UCTMCTS(env, iterations=50, exploration_constant=1.41, rollout_depth=10)\n",
    "\n",
    "\n",
    "done = False\n",
    "scores = []\n",
    "for i in range(10):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        root = UCTNode(state, env.score)  # Initialize the root node for MCTS\n",
    "\n",
    "        # Run multiple simulations to construct and refine the search tree\n",
    "        for _ in range(uct_mcts.iterations):\n",
    "            uct_mcts.run_simulation(root)\n",
    "\n",
    "        # Select the best action based on the visit distribution of the root's children\n",
    "        best_action, visit_distribution = uct_mcts.best_action_distribution(root)\n",
    "        # print(\n",
    "        #    \"MCTS selected action:\",\n",
    "        #    best_action,\n",
    "        #    \"with visit distribution:\",\n",
    "        #    visit_distribution,\n",
    "        # )\n",
    "\n",
    "        state, reward, done, _ = env.step(best_action)\n",
    "        env.render(action=best_action)  # Display the updated game state\n",
    "    scores.append(env.score)\n",
    "\n",
    "print(\"Average score over 10 games:\", np.mean(scores))\n",
    "print(\"Game over, final score:\", env.score)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69eZPCYs40d0"
   },
   "source": [
    "## **2048 TD Learning with N-Tuple Approximation**\n",
    "\n",
    "### **What We Are Doing**\n",
    "\n",
    "- We use **Temporal Difference (TD) learning** to train an **N-Tuple function approximator**.\n",
    "- This approximator **estimates the value of a game state**, improving decision-making in 2048.\n",
    "- Instead of storing every state, we utilize **small tile patterns (n-tuples)** to approximate the game board.\n",
    "- Training involves **playing thousands of games** while updating weights based on rewards.\n",
    "\n",
    "### **How It Works**\n",
    "\n",
    "1. **Define N-Tuple Patterns**\n",
    "\n",
    "   - These are small tile groups (e.g., rows, squares) used for function approximation.\n",
    "   - **Rotations and flips** are applied to reduce redundancy and improve generalization.\n",
    "\n",
    "2. **TD Learning Process**\n",
    "\n",
    "   - The agent **plays games and learns** by updating value estimates.\n",
    "   - An **Œµ-greedy policy** is used to balance exploration and exploitation.\n",
    "   - **Weights are updated** based on the difference between **predicted** and **actual** rewards.\n",
    "\n",
    "3. **Train and Evaluate**\n",
    "   - We run **thousands of episodes** to refine the approximation.\n",
    "   - Game performance is logged, tracking **final scores** and **how often the agent reaches 2048**.\n",
    "\n",
    "**Note:** There are no strict implementation rules for TD-learning‚Äîdesign your own pattern and implement TD-learning in any form (e.g., **TD(0), Multi-stage TD, or any TD variant**). However, remember to **briefly describe your approach** in the question later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-09T15:02:50.014109Z",
     "iopub.status.busy": "2025-04-09T15:02:50.013961Z",
     "iopub.status.idle": "2025-04-09T15:02:50.032641Z",
     "shell.execute_reply": "2025-04-09T15:02:50.032138Z"
    },
    "id": "-brvr3PWm4aT",
    "outputId": "0dcfb8c0-c40d-40c9-bfd3-fbb11e74efe7"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# TODO: Define transformation functions (rotation and reflection), i.e., rot90, rot180, ..., etc.\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "class NTupleApproximator:\n",
    "    def __init__(self, board_size, patterns):\n",
    "        \"\"\"\n",
    "        Initializes the N-Tuple approximator.\n",
    "        Hint: you can adjust these if you want\n",
    "        \"\"\"\n",
    "        self.board_size = board_size\n",
    "        self.patterns = patterns\n",
    "        # Create a weight dictionary for each pattern (shared within a pattern group)\n",
    "        # self.weights = [defaultdict(float) for _ in patterns]\n",
    "        self.weights = []\n",
    "        # Generate symmetrical transformations for each pattern\n",
    "        self.symmetry_patterns = []\n",
    "\n",
    "        for pattern in self.patterns:\n",
    "            syms = self.generate_symmetries(pattern)\n",
    "            self.symmetry_patterns += syms\n",
    "            self.weights += [defaultdict(float)] * len(syms)  # shared weight\n",
    "            # for syms_ in syms:\n",
    "            #    self.symmetry_patterns.append(syms_ )\n",
    "            #    self.weights[str(syms_)] += self.weights[str(pattern)]\n",
    "        assert len(self.weights) == len(self.symmetry_patterns)\n",
    "        # print(f\"Number of patterns: {len(self.symmetry_patterns)}\")\n",
    "\n",
    "        # for p in self.symmetry_patterns:\n",
    "        #     print(p)\n",
    "\n",
    "    def generate_symmetries(self, pattern):\n",
    "        # TODO: Generate 8 symmetrical transformations of the given pattern.\n",
    "        ordered_pattern = np.full_like(pattern, -1, dtype=np.int32)\n",
    "        cnt = 0\n",
    "        for i in range(ordered_pattern.shape[0]):\n",
    "            for j in range(ordered_pattern.shape[1]):\n",
    "                if pattern[i, j]:\n",
    "                    ordered_pattern[i, j] = cnt\n",
    "                    cnt += 1\n",
    "\n",
    "        ordered_syms = [\n",
    "            ordered_pattern,\n",
    "            np.rot90(ordered_pattern, 1),\n",
    "            np.rot90(ordered_pattern, 2),\n",
    "            np.rot90(ordered_pattern, 3),\n",
    "        ]\n",
    "        if not np.array_equal(pattern, patterns[-1]):\n",
    "            ordered_syms += [np.fliplr(s) for s in ordered_syms]\n",
    "\n",
    "        # ordered_syms = [ordered_pattern]\n",
    "\n",
    "        # print(len(ordered_syms))\n",
    "        coord_syms = []\n",
    "        for order in ordered_syms:\n",
    "            coords = [None] * cnt\n",
    "            for i in range(order.shape[0]):\n",
    "                for j in range(order.shape[1]):\n",
    "                    if order[i, j] != -1:\n",
    "                        coords[order[i, j]] = (i, j)\n",
    "            coord_syms.append(coords)\n",
    "        return coord_syms\n",
    "\n",
    "    def tile_to_index(self, tile):\n",
    "        \"\"\"\n",
    "        Converts tile values to an index for the lookup table.\n",
    "        \"\"\"\n",
    "        if tile == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return int(math.log(tile, 2))\n",
    "\n",
    "    def get_feature(self, board):  # , coords):\n",
    "        # TODO: Extract tile values from the board based on the given coordinates and convert them into a feature tuple.\n",
    "        # print(board)\n",
    "        return [\n",
    "            tuple(board[coord] for coord in coords) for coords in self.symmetry_patterns\n",
    "        ]\n",
    "        print(ret)\n",
    "        return ret\n",
    "\n",
    "    def value(self, board):\n",
    "        # TODO: Estimate the board value: sum the evaluations from all patterns.\n",
    "        # print(self.get_feature(board))\n",
    "        features = self.get_feature(board)\n",
    "        return np.mean([w[f] for w, f in zip(self.weights, features)])\n",
    "\n",
    "    def update(self, board, delta, alpha):\n",
    "        # TODO: Update weights based on the TD error.\n",
    "        features = self.get_feature(board)\n",
    "        for w, f in zip(self.weights, features):\n",
    "            w[f] += alpha * delta\n",
    "\n",
    "\n",
    "# my add\n",
    "def simulate(sim_env, action, board):\n",
    "    # sim_env.board = board.copy()\n",
    "    # sim_env.score = 0\n",
    "    sim_env.reset(board, 0)\n",
    "    sim_state, reward, _, afterstate = sim_env.step(action)\n",
    "    return afterstate, reward\n",
    "\n",
    "\n",
    "def find_best_action(approximator, sim_env, board, gamma=0.99):\n",
    "    max_a = None\n",
    "    max_value = -np.inf\n",
    "    #  sim_env.board = board.copy()\n",
    "    sim_env.reset(state=board)\n",
    "    legal_moves = [a for a in range(4) if sim_env.is_move_legal(a)]\n",
    "    # print(board)\n",
    "    # print()\n",
    "    for action in legal_moves:\n",
    "        afterstate, reward = simulate(sim_env, action, board)\n",
    "\n",
    "        sim_value = reward + approximator.value(afterstate)\n",
    "        # print(reward, approximator.value(afterstate))\n",
    "        # print(afterstate)\n",
    "        # print()\n",
    "        if sim_value > max_value:\n",
    "            max_value = sim_value\n",
    "            max_a = action\n",
    "    # print(\"===\")\n",
    "    return max_a\n",
    "\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Transition = namedtuple(\"Transition\", \"s_after, s_next\")\n",
    "\n",
    "\n",
    "def td_learning(\n",
    "    env, approximator, num_episodes=50000, alpha=0.01, gamma=0.99, epsilon=0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the 2048 agent using TD-Learning.\n",
    "\n",
    "    Args:\n",
    "        env: The 2048 game environment.\n",
    "        approximator: NTupleApproximator instance.\n",
    "        num_episodes: Number of training episodes.\n",
    "        alpha: Learning rate.\n",
    "        gamma: Discount factor.\n",
    "        epsilon: Epsilon-greedy exploration rate.\n",
    "    \"\"\"\n",
    "    final_scores = []\n",
    "    success_flags = []\n",
    "\n",
    "    sim_env = copy.deepcopy(env)\n",
    "    max_tiles = {}\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        trajectory = []  # Store trajectory data if needed\n",
    "        previous_score = 0\n",
    "        done = False\n",
    "        # max_tile = np.max(state)\n",
    "\n",
    "        print(f\"\\r{episode+1}/{num_episodes}\", end=\"\")\n",
    "        while not done:\n",
    "            legal_moves = [a for a in range(4) if env.is_move_legal(a)]\n",
    "            if not legal_moves:\n",
    "                break\n",
    "            # TODO: action selection\n",
    "            # Note: TD learning works fine on 2048 without explicit exploration, but you can still try some exploration methods.\n",
    "            # if np.random.random() < epsilon:\n",
    "            #    action = random.choice(legal_moves)\n",
    "            # else:\n",
    "            action = find_best_action(approximator, sim_env, state, gamma)\n",
    "\n",
    "            next_state, new_score, done, afterstate = env.step(action)\n",
    "            trajectory.append(Transition(afterstate, next_state))\n",
    "            incremental_reward = new_score - previous_score\n",
    "\n",
    "            previous_score = new_score\n",
    "            state = next_state\n",
    "            # print(action)\n",
    "            # print(new_score)\n",
    "            # print(state)\n",
    "\n",
    "        max_tile = np.max(state)  # increasing, only check when done\n",
    "        # print(f\"\\r{max_tile}   \", end=\"\")\n",
    "        max_tiles[max_tile] = max_tiles.get(max_tile, 0) + 1\n",
    "\n",
    "        for s_after, s_next in reversed(trajectory[:-1]):\n",
    "            a_next = find_best_action(approximator, sim_env, s_next)\n",
    "            s_after_next, r_next = simulate(sim_env, a_next, s_next)\n",
    "            delta = (\n",
    "                r_next + approximator.value(s_after_next) - approximator.value(s_after)\n",
    "            )\n",
    "            approximator.update(s_after, delta, alpha)\n",
    "\n",
    "        final_scores.append(env.score)\n",
    "        success_flags.append(1 if max_tile >= 2048 else 0)\n",
    "\n",
    "        # epsilon = max(0.01, epsilon * 0.996)\n",
    "\n",
    "        if (episode + 1) % 100 == 0:\n",
    "            avg_score = np.mean(final_scores[-100:])\n",
    "            success_rate = np.sum(success_flags[-100:]) / 100\n",
    "            print(\n",
    "                f\"Episode {episode+1}/{num_episodes} | Avg Score: {avg_score:.2f} | Success Rate: {success_rate:.2f}\"\n",
    "            )\n",
    "            vals = list(approximator.weights[0].values())\n",
    "            # print(max(vals), min(vals), np.mean(vals))\n",
    "            # print(f\"{alpha=}\")\n",
    "            # print(max_tiles)\n",
    "            max_tiles = {}\n",
    "            # print(approximator.weights)\n",
    "\n",
    "    return final_scores\n",
    "\n",
    "\n",
    "# TODO: Define your own n-tuple patterns\n",
    "# fmt: off\n",
    "patterns = [\n",
    "    [\n",
    "        [1, 1, 1, 1],\n",
    "        [1, 1, 0, 0],\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 0, 0, 0]\n",
    "    ],\n",
    "    [\n",
    "        [0, 0, 0, 0],\n",
    "        [1, 1, 1, 1],\n",
    "        [1, 1, 0, 0],\n",
    "        [0, 0, 0, 0]\n",
    "    ],\n",
    "    #[\n",
    "    #    [0, 0, 0, 0],\n",
    "    #    [0, 0, 0, 0],\n",
    "    #    [1, 1, 1, 1],\n",
    "    #    [1, 1, 0, 0],\n",
    "    #],\n",
    "    [\n",
    "        [1, 1, 1, 0],\n",
    "        [1, 1, 1, 0],\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 0, 0, 0]\n",
    "    ],\n",
    "    [\n",
    "        [0, 0, 0, 0],\n",
    "        [1, 1, 1, 0],\n",
    "        [1, 1, 1, 0],\n",
    "        [0, 0, 0, 0]\n",
    "    ],\n",
    "]\n",
    "# fmt: on\n",
    "patterns = [np.array(l) == 1 for l in patterns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T15:02:50.034028Z",
     "iopub.status.busy": "2025-04-09T15:02:50.033890Z",
     "iopub.status.idle": "2025-04-09T15:38:16.574523Z",
     "shell.execute_reply": "2025-04-09T15:38:16.573875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/1000Episode 100/1000 | Avg Score: 3308.00 | Success Rate: 0.00\n",
      "200/1000Episode 200/1000 | Avg Score: 4063.56 | Success Rate: 0.00\n",
      "300/1000Episode 300/1000 | Avg Score: 6052.32 | Success Rate: 0.00\n",
      "400/1000Episode 400/1000 | Avg Score: 6974.84 | Success Rate: 0.00\n",
      "500/1000Episode 500/1000 | Avg Score: 6953.88 | Success Rate: 0.00\n",
      "600/1000Episode 600/1000 | Avg Score: 7653.52 | Success Rate: 0.00\n",
      "700/1000Episode 700/1000 | Avg Score: 8248.88 | Success Rate: 0.00\n",
      "800/1000Episode 800/1000 | Avg Score: 7636.80 | Success Rate: 0.00\n",
      "900/1000Episode 900/1000 | Avg Score: 8103.88 | Success Rate: 0.00\n",
      "1000/1000Episode 1000/1000 | Avg Score: 9201.00 | Success Rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "approximator = NTupleApproximator(board_size=4, patterns=patterns)\n",
    "\n",
    "env = Game2048Env()\n",
    "\n",
    "# Run TD-Learning training\n",
    "# Note: To achieve significantly better performance, you will likely need to train for over 100,000 episodes.\n",
    "# However, to quickly verify that your implementation is working correctly, you can start by running it for 1,000 episodes before scaling up.\n",
    "import os\n",
    "\n",
    "# if os.path.exists(\"weights.pkl\"):\n",
    "#    import pickle\n",
    "#\n",
    "#    with open(\"weights.pkl\", \"rb\") as f:\n",
    "#        approximator.weights = pickle.load(f)\n",
    "# else:\n",
    "final_scores = td_learning(\n",
    "    env, approximator, num_episodes=1000, alpha=0.1, gamma=0.99, epsilon=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open(\"weights.pkl\", \"wb\") as f:\n",
    "    pickle.dump(approximator.weights, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eczy63SGkP-p"
   },
   "source": [
    "**Question**: You are expected to provide a detailed explanation of your n-tuple design and TD-learning implementation.\n",
    "Additionally, you should discuss specific details such as:\n",
    "\n",
    "1Ô∏è‚É£ n-Tuple Design\n",
    "\n",
    "2Ô∏è‚É£ TD-Learning Implementation\n",
    "Is the board evaluated before or after adding a random tile?\n",
    "Is future board evaluation based on a single state or multiple states?\n",
    "Any other important details in your implementation?\n",
    "\n",
    "3Ô∏è‚É£ Training Results\n",
    "Provide a graph showing training steps vs. score progression.\n",
    "**_Note: Ensure the explanation matches the implementation, or points will be deducted._**\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "1.\n",
    "\n",
    "Four 6-tuple from paper.\n",
    "\n",
    "```\n",
    "[\n",
    "\t[1, 1, 1, 1],\n",
    "\t[1, 1, 0, 0],\n",
    "\t[0, 0, 0, 0],\n",
    "\t[0, 0, 0, 0]\n",
    "],\n",
    "[\n",
    "\t[0, 0, 0, 0],\n",
    "\t[1, 1, 1, 1],\n",
    "\t[1, 1, 0, 0],\n",
    "\t[0, 0, 0, 0]\n",
    "],\n",
    "\n",
    "[\n",
    "\t[1, 1, 1, 0],\n",
    "\t[1, 1, 1, 0],\n",
    "\t[0, 0, 0, 0],\n",
    "\t[0, 0, 0, 0]\n",
    "],\n",
    "[\n",
    "\t[0, 0, 0, 0],\n",
    "\t[1, 1, 1, 0],\n",
    "\t[1, 1, 1, 0],\n",
    "\t[0, 0, 0, 0]\n",
    "]\n",
    "```\n",
    "\n",
    "Reference:\n",
    "K.-H. Yeh, I-C. Wu, C.-H. Hsueh, C.-C. Chang, C.- . iang, and H. hiang, ‚ÄúMultistage\n",
    "temporal difference learning for 2048-like games,‚Äù IEEE Trans. Comput. Intell. AI\n",
    "Games, vol. 9, no. 4, pp. 369‚Äì380, Dec. 2017, doi: 10.1109/TCIAIG.2016.2593710.\n",
    "[Online]. Available: arXiv:1606.07374.\n",
    "\n",
    "2.\n",
    "\n",
    "After adding a random tile because I use the board returned by env.step.\n",
    "Single state only, no search, just TD(0).\n",
    "\n",
    "3.\n",
    "\n",
    "Generated below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T15:38:16.576206Z",
     "iopub.status.busy": "2025-04-09T15:38:16.576056Z",
     "iopub.status.idle": "2025-04-09T15:38:16.668018Z",
     "shell.execute_reply": "2025-04-09T15:38:16.667486Z"
    }
   },
   "source": [
    "# means = [np.mean(final_scores[i : i + 50]) for i in range(0, len(final_scores), 50)]\n",
    "# steps = [i for i in range(50, len(final_scores) + 1, 50)]\n",
    "plt.plot(range(len(final_scores)), final_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeUw9mAe596F"
   },
   "source": [
    "### Playing 2048 Using TD-Learned N-Tuple Approximation\n",
    "\n",
    "In this section, we will play 2048 using the N-Tuple function approximator trained with TD learning. Instead of random play or MCTS, the agent will now evaluate board states using learned value estimates to make more informed decisions.\n",
    "\n",
    "By using the trained approximator, the agent selects actions based on state value predictions, improving decision-making compared to random moves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T15:38:16.669523Z",
     "iopub.status.busy": "2025-04-09T15:38:16.669368Z",
     "iopub.status.idle": "2025-04-09T15:38:17.427807Z",
     "shell.execute_reply": "2025-04-09T15:38:17.427200Z"
    },
    "id": "SpM5WLF67biN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game over, final score: 12072\n"
     ]
    }
   ],
   "source": [
    "import copy  # Used for deep copying the environment\n",
    "import random\n",
    "\n",
    "# Initialize the game environment\n",
    "state = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "\n",
    "sim_env = copy.deepcopy(env)\n",
    "previous_score = 0\n",
    "\n",
    "while not done:\n",
    "\n",
    "    legal_moves = [a for a in range(4) if env.is_move_legal(a)]\n",
    "    if not legal_moves:\n",
    "        break\n",
    "\n",
    "    # TODO: Use your N-Tuple approximator to play 2048\n",
    "    best_action = find_best_action(approximator, sim_env, state)\n",
    "\n",
    "    action = best_action  # Choose the best action based on evaluation\n",
    "    state, reward, done, _ = env.step(action)  # Apply the selected action\n",
    "    env.render(action=action)  # Display the updated game state\n",
    "\n",
    "    previous_score = reward\n",
    "\n",
    "# Print final game results\n",
    "print(\"Game over, final score:\", env.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTGF3mEe78u2"
   },
   "source": [
    "## **Integrating TD-Learned N-Tuple Approximation into MCTS**\n",
    "\n",
    "### **What We Are Doing?**\n",
    "\n",
    "- We are improving **Monte Carlo Tree Search (MCTS)** by integrating our **trained N-Tuple approximator**.\n",
    "- Instead of relying only on **random rollouts**, we now **estimate state values using TD-learning**.\n",
    "- This helps **MCTS make more accurate decisions**, especially in deeper searches.\n",
    "\n",
    "### **Key Modifications**\n",
    "\n",
    "1. **Using TD-Learned N-Tuple Approximation for Leaf Evaluation**\n",
    "\n",
    "   - Instead of running **random rollouts**, we **evaluate leaf nodes** using the **trained approximator**.\n",
    "   - This allows MCTS to **assess states more intelligently**.\n",
    "\n",
    "2. **Modified Rollout Phase**\n",
    "\n",
    "   - Instead of pure random rollouts, we:\n",
    "     - Play a **few random moves** (to allow some exploration).\n",
    "     - **Use the approximator to evaluate the final state**.\n",
    "   - This results in **faster and more accurate rollouts**.\n",
    "\n",
    "3. **Tree Search Steps Remain the Same**\n",
    "   - **Selection** ‚Äì Traverse the search tree using **UCT**.\n",
    "   - **Expansion** ‚Äì Add new nodes to explore untried actions.\n",
    "   - **Backpropagation** ‚Äì Update rewards and visit counts.\n",
    "\n",
    "### **NOTE: Do We Still Need Rollouts?**\n",
    "\n",
    "- Since **N-Tuple learning already estimates state values**, we **might not need random rollouts**.\n",
    "- However, **a few rollout moves** can help **reduce bias** and **improve exploration**.\n",
    "- This balance can be **tuned as a hyperparameter**.\n",
    "\n",
    "This approach **combines learning-based evaluation with tree search**, making MCTS much more efficient for 2048! üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "execution": {
     "iopub.execute_input": "2025-04-09T15:38:17.429512Z",
     "iopub.status.busy": "2025-04-09T15:38:17.429357Z",
     "iopub.status.idle": "2025-04-09T15:38:17.442883Z",
     "shell.execute_reply": "2025-04-09T15:38:17.442398Z"
    },
    "id": "bhjbJHHt38KX",
    "outputId": "e90892fe-9826-4527-9661-2c31698f9f7b"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Note: This MCTS implementation is almost identical to the previous one,\n",
    "# except for the rollout phase, which now incorporates the approximator.\n",
    "\n",
    "\n",
    "# Node for TD-MCTS using the TD-trained value approximator\n",
    "class TD_MCTS_Node:\n",
    "    def __init__(self, state, score, parent=None, action=None):\n",
    "        \"\"\"\n",
    "        state: current board state (numpy array)\n",
    "        score: cumulative score at this node\n",
    "        parent: parent node (None for root)\n",
    "        action: action taken from parent to reach this node\n",
    "        \"\"\"\n",
    "        self.state = state\n",
    "        self.score = score\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.children = {}\n",
    "        self.visits = 0\n",
    "        self.total_reward = 0.0\n",
    "        # List of untried actions based on the current state's legal moves\n",
    "        self.untried_actions = [a for a in range(4) if env.is_move_legal(a)]\n",
    "\n",
    "    def fully_expanded(self):\n",
    "        # A node is fully expanded if no legal actions remain untried.\n",
    "        return len(self.untried_actions) == 0\n",
    "\n",
    "\n",
    "# TD-MCTS class utilizing a trained approximator for leaf evaluation\n",
    "class TD_MCTS:\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        approximator,\n",
    "        iterations=500,\n",
    "        exploration_constant=1.41,\n",
    "        rollout_depth=10,\n",
    "        gamma=0.99,\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.approximator = approximator\n",
    "        self.iterations = iterations\n",
    "        self.c = exploration_constant\n",
    "        self.rollout_depth = rollout_depth\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def create_env_from_state(self, state, score):\n",
    "        # Create a deep copy of the environment with the given state and score.\n",
    "        # new_env = Game2048Env()\n",
    "        # new_env.reset(state, score)\n",
    "        # return new_env\n",
    "        new_env = copy.deepcopy(self.env)\n",
    "        new_env.board = state.copy()\n",
    "        new_env.score = score\n",
    "        return new_env\n",
    "\n",
    "    def select_child(self, node):\n",
    "        # TODO: Use the UCT formula: Q + c * sqrt(log(parent.visits)/child.visits) to select the best child.\n",
    "        if len(node.untried_actions) != 0:\n",
    "            return node.children[node.untried_actions[0]]\n",
    "        else:\n",
    "            uct_max = -np.inf\n",
    "            child_max = None\n",
    "            for action, child in node.children.items():\n",
    "                uct_value = child.total_reward / child.visits + self.c * np.sqrt(\n",
    "                    np.log(node.visits) / child.visits\n",
    "                )\n",
    "                if uct_value > uct_max:\n",
    "                    uct_max = uct_value\n",
    "                    child_max = child\n",
    "\n",
    "            return child_max\n",
    "\n",
    "    def rollout(self, sim_env, depth):\n",
    "        # TODO: Perform a random rollout until reaching the maximum depth or a terminal state.\n",
    "        # TODO: Use the approximator to evaluate the final state.\n",
    "        # score = sim_env.score\n",
    "        state = sim_env.board.copy()\n",
    "        while not sim_env.is_game_over() and depth > 0:\n",
    "            legal_moves = [a for a in range(4) if sim_env.is_move_legal(a)]\n",
    "            if len(legal_moves) == 0:\n",
    "                break\n",
    "            action = random.choice(legal_moves)\n",
    "            state, _, done, _ = sim_env.step(action)\n",
    "            depth -= 1\n",
    "\n",
    "        # aproximator only tells future score, also need to add current score\n",
    "        return sim_env.score + self.approximator.value(state)\n",
    "\n",
    "    def backpropagate(self, node, reward):\n",
    "        # TODO: Propagate the obtained reward back up the tree.\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.total_reward += reward\n",
    "            node = node.parent\n",
    "\n",
    "    def run_simulation(self, root):\n",
    "        node = root\n",
    "\n",
    "        # TODO: Selection: Traverse the tree until reaching an unexpanded node.\n",
    "        while node.fully_expanded():\n",
    "            child = self.select_child(node)\n",
    "            if child is None:\n",
    "                break\n",
    "            node = child\n",
    "\n",
    "        sim_env = self.create_env_from_state(node.state, node.score)\n",
    "\n",
    "        # TODO: Expansion: If the node is not terminal, expand an untried action.\n",
    "        if len(node.untried_actions) != 0:\n",
    "            action = random.choice(node.untried_actions)\n",
    "            node.untried_actions.remove(action)\n",
    "            state, score, done, _ = sim_env.step(action)\n",
    "            expanded_node = TD_MCTS_Node(state, score)\n",
    "            node.children[action] = expanded_node\n",
    "            expanded_node.parent = node\n",
    "            node = expanded_node\n",
    "\n",
    "        # Rollout: Simulate a random game from the expanded node.\n",
    "        rollout_reward = self.rollout(sim_env, self.rollout_depth)\n",
    "        # Backpropagate the obtained reward.\n",
    "        self.backpropagate(node, rollout_reward)\n",
    "\n",
    "    def best_action_distribution(self, root):\n",
    "        # Compute the normalized visit count distribution for each child of the root.\n",
    "        total_visits = sum(child.visits for child in root.children.values())\n",
    "        distribution = np.zeros(4)\n",
    "        best_visits = -1\n",
    "        best_action = None\n",
    "        for action, child in root.children.items():\n",
    "            distribution[action] = (\n",
    "                child.visits / total_visits if total_visits > 0 else 0\n",
    "            )\n",
    "            if child.visits > best_visits:\n",
    "                best_visits = child.visits\n",
    "                best_action = action\n",
    "        return best_action, distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1a_FgM87pJkX"
   },
   "source": [
    "**Question**: Clearly explain how you integrate the value approximator into MCTS to enhance decision-making.\n",
    "\n",
    "**Answer**:\n",
    "TD-MCTS consider the future score provided by the approximator, giving more accurate evaluation than vanilla MCTS that only consider current score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxh3fbJJ8wDt"
   },
   "source": [
    "### **Playing 2048 Using TD-MCTS with Trained N-Tuple Table**\n",
    "\n",
    "- We are now playing **2048 using TD-MCTS**, which **combines tree search with our trained N-Tuple approximator**.\n",
    "- The **MCTS tree search** helps explore possible actions, while **TD-learned state values** guide decision-making.\n",
    "- This method **improves over pure MCTS** by providing **more accurate rollout estimates**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T15:38:17.444412Z",
     "iopub.status.busy": "2025-04-09T15:38:17.444266Z",
     "iopub.status.idle": "2025-04-09T16:11:03.567783Z",
     "shell.execute_reply": "2025-04-09T16:11:03.567331Z"
    },
    "id": "cedh4sP86ohp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 2\n",
      "TD-MCTS selected action: 0\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 1\n",
      "TD-MCTS selected action: 3\n",
      "TD-MCTS selected action: 3\n",
      "Game over, final score: 6348\n"
     ]
    }
   ],
   "source": [
    "td_mcts = TD_MCTS(\n",
    "    env,\n",
    "    approximator,\n",
    "    iterations=50,\n",
    "    exploration_constant=1.41,\n",
    "    rollout_depth=10,\n",
    "    gamma=0.99,\n",
    ")\n",
    "\n",
    "state = env.reset()\n",
    "env.render()\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    # Create the root node from the current state\n",
    "    root = TD_MCTS_Node(state, env.score)\n",
    "\n",
    "    # Run multiple simulations to build the MCTS tree\n",
    "    for _ in range(td_mcts.iterations):\n",
    "        td_mcts.run_simulation(root)\n",
    "\n",
    "    # Select the best action (based on highest visit count)\n",
    "    best_act, _ = td_mcts.best_action_distribution(root)\n",
    "    print(\"TD-MCTS selected action:\", best_act)\n",
    "\n",
    "    # Execute the selected action and update the state\n",
    "    state, reward, done, _ = env.step(best_act)\n",
    "    env.render(action=best_act)\n",
    "\n",
    "print(\"Game over, final score:\", env.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URuUldZKIa6j"
   },
   "source": [
    "# **Question 2: Self-Play Reinforcement Learning with PUCT-MCTS for 2048**\n",
    "\n",
    "## **What We Are Doing**\n",
    "\n",
    "In this question, you will implement a **self-play reinforcement learning process** similar to **AlphaZero**, but without neural networks. Instead, we will use **Monte Carlo Tree Search (MCTS)** to train a **policy approximator**, then integrate it into **PUCT-MCTS** for improved decision-making in 2048.\n",
    "\n",
    "AlphaZero demonstrated that **combining self-play with MCTS and policy-value learning** leads to **superhuman performance** in games like Go and Chess. We will apply the same idea to **2048**, but using:\n",
    "\n",
    "- **A policy approximator** (table-based, learned from MCTS visit counts).\n",
    "- **A value approximator** (TD-learning with n-tuple features).\n",
    "- **PUCT (Predictor + UCT) MCTS** to efficiently balance **exploration and exploitation**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Steps**\n",
    "\n",
    "### **1. Train a Policy Approximator Using MCTS Self-Play**\n",
    "\n",
    "- Run **MCTS simulations** and record the **visit count distribution** for each state.\n",
    "- Use these distributions to **train a policy approximator** that predicts MCTS move probabilities.\n",
    "\n",
    "### **2. Implement PUCT-MCTS (MCTS with Policy Guidance)**\n",
    "\n",
    "- Modify **MCTS selection** to use the **PUCT formula**, combining:\n",
    "  - **Value estimates** from TD-learning.\n",
    "  - **Action priors** from the trained policy approximator.\n",
    "\n",
    "$PUCT(s, a) = Q(s, a) + c_{puct} \\cdot P(s, a) \\cdot \\frac{\\sqrt{N(s)}}{1 + N(s, a)}$\n",
    "\n",
    "- This allows the **search tree to focus on promising moves earlier**, improving efficiency.\n",
    "\n",
    "### **3. Further Improve Policy & Value Approximators with Self-Play**\n",
    "\n",
    "- Continue **self-play training**, updating:\n",
    "  - The **policy approximator** using **PUCT visit counts**.\n",
    "  - The **value approximator** using **MCTS Q-values**.\n",
    "- Over time, the learned policy can guide search more efficiently, reducing reliance on full MCTS simulations,\n",
    "  while the value approximator enhances search by providing stronger state evaluations.\n",
    "\n",
    "---\n",
    "\n",
    "## **Why This Works (Inspired by AlphaZero)**\n",
    "\n",
    "- **MCTS alone is computationally expensive**‚Äîadding a learned policy makes it much **faster and more efficient**.\n",
    "- **Self-play allows the agent to improve over time**, adapting to new strategies.\n",
    "- **Combining policy + value functions with PUCT makes MCTS significantly stronger**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2rSE8Z_9hLe"
   },
   "source": [
    "## **Training a Policy Approximator Using MCTS (Inspired by AlphaZero)**\n",
    "\n",
    "### **What We Are Doing**\n",
    "\n",
    "- We use **TD-MCTS** to generate training data for a **policy approximator**.\n",
    "- The policy approximator **learns action probabilities** from **MCTS visit distributions**.\n",
    "- After training, the policy will be **used later in PUCT-MCTS**.\n",
    "\n",
    "### **Key Steps**\n",
    "\n",
    "1. **Run TD-MCTS on multiple games** to collect **state-action visit distributions**.\n",
    "2. **Train the policy approximator** by updating it toward MCTS action distributions.\n",
    "3. **Use the policy later** to improve **MCTS efficiency** (PUCT).\n",
    "\n",
    "### **Why This Works**\n",
    "\n",
    "- **MCTS alone** explores actions based on visit counts, which is **computationally expensive**.\n",
    "- **A trained policy** helps guide MCTS **more efficiently**.\n",
    "- Later, **we integrate this into PUCT-MCTS for better exploration**.\n",
    "\n",
    "üéØ **How to Earn 15 Points?**\n",
    "\n",
    "1Ô∏è‚É£ Correct Implementation of Policy Approximator and Training with MCTS\n",
    "\n",
    "- Successfully implement a **policy approximator** and train it using **MCTS**.(6 points)\n",
    "  - üî• **Your policy must achieve better performance than a random agent to be considered successfully trained.**\n",
    "- Discussion of the policy approximator\n",
    "\n",
    "2Ô∏è‚É£ Implementation of MCTS with PUCT Formula + Explanation (5 points)\n",
    "\n",
    "- Implement **Monte Carlo Tree Search (MCTS)** with the **PUCT formula**.\n",
    "- **Note:** Points may be deducted for:\n",
    "  - Errors in the PUCT formula.\n",
    "  - Incorrect function implementations.\n",
    "\n",
    "3Ô∏è‚É£ Implementation of Policy & Value Approximators with Self-Play (4 points)\n",
    "\n",
    "- Implement **self-play training** with both **policy & value approximators**.\n",
    "- The improved approximators should produce **more accurate value estimations**, leading to **better performance than previous versions**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:11:03.569490Z",
     "iopub.status.busy": "2025-04-09T16:11:03.569340Z",
     "iopub.status.idle": "2025-04-09T16:11:03.581002Z",
     "shell.execute_reply": "2025-04-09T16:11:03.580610Z"
    },
    "id": "rNi0p1aQjr3w"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# TODO: Define the action transformation functions (i.e., rot90_action, rot180_action, etc.)\n",
    "# Note: You have already defined transformation functions for patterns before.\n",
    "\n",
    "\n",
    "# Note: PolicyApproximator is similar to the value approximator but differs in key aspects.\n",
    "class PolicyApproximator:\n",
    "    def __init__(self, board_size, patterns):\n",
    "        \"\"\"\n",
    "        Initializes the N-Tuple approximator.\n",
    "        Hint: you can adjust these if you want.\n",
    "        \"\"\"\n",
    "        self.board_size = board_size\n",
    "        self.patterns = patterns\n",
    "        self.actions = [0, 1, 2, 3]\n",
    "        # Weight structure: [pattern_idx][feature_key][action]\n",
    "        self.weights = []\n",
    "        # Generate the 8 symmetrical transformations for each pattern and store their types.\n",
    "        self.symmetry_patterns = []\n",
    "        self.symmetry_types = (\n",
    "            []\n",
    "        )  # Store the type of symmetry transformation (rotation or reflection)\n",
    "\n",
    "        for pattern in self.patterns:\n",
    "            syms, types = self.generate_symmetries(pattern)\n",
    "            self.weights += [defaultdict(lambda: np.full(4, 1 / 4))] * len(syms)\n",
    "            self.symmetry_patterns.extend(syms)\n",
    "            self.symmetry_types.extend(types)\n",
    "            assert len(syms) == len(types)\n",
    "        self.rsymmetry_types = [\n",
    "            [order.index(i) for i in range(4)] for order in self.symmetry_types\n",
    "        ]\n",
    "\n",
    "        # TODO: Define corresponding action transformation functions for each symmetry.\n",
    "\n",
    "    def generate_symmetries(self, pattern):\n",
    "        # TODO: Generate 8 symmetrical transformations of the given pattern.\n",
    "        ordered_pattern = np.full_like(pattern, -1, dtype=np.int32)\n",
    "        cnt = 0\n",
    "        for i in range(ordered_pattern.shape[0]):\n",
    "            for j in range(ordered_pattern.shape[1]):\n",
    "                if pattern[i, j]:\n",
    "                    ordered_pattern[i, j] = cnt\n",
    "                    cnt += 1\n",
    "\n",
    "        ordered_syms = [\n",
    "            ordered_pattern,\n",
    "            np.rot90(ordered_pattern, 1),\n",
    "            np.rot90(ordered_pattern, 2),\n",
    "            np.rot90(ordered_pattern, 3),\n",
    "        ]\n",
    "        if not np.array_equal(pattern, patterns[-1]):\n",
    "            ordered_syms += [np.fliplr(s) for s in ordered_syms]\n",
    "        # print(ordered_syms)\n",
    "        coord_syms = []\n",
    "        for order in ordered_syms:\n",
    "            coords = [None] * cnt\n",
    "            for i in range(order.shape[0]):\n",
    "                for j in range(order.shape[1]):\n",
    "                    if order[i, j] != -1:\n",
    "                        coords[order[i, j]] = (i, j)\n",
    "            coord_syms.append(coords)\n",
    "        action_orders = [\n",
    "            [0, 1, 2, 3],\n",
    "            [3, 2, 0, 1],\n",
    "            [1, 0, 3, 2],\n",
    "            [2, 3, 1, 0],\n",
    "        ]\n",
    "        # fliplr\n",
    "        if not np.array_equal(pattern, patterns[-1]):\n",
    "            action_orders += [[o[0], o[1], o[3], o[2]] for o in action_orders]\n",
    "        return coord_syms, action_orders\n",
    "\n",
    "    def tile_to_index(self, tile):\n",
    "        return 0 if tile == 0 else int(math.log(tile, 2))\n",
    "\n",
    "    def get_feature(self, board):  # , coords):\n",
    "        # TODO: Extract tile values from the board based on the given coordinates and convert them into a feature tuple.\n",
    "        return [\n",
    "            tuple(board[coord] for coord in coords) for coords in self.symmetry_patterns\n",
    "        ]\n",
    "\n",
    "    def get_action_values(self, features):\n",
    "        return np.mean(\n",
    "            [\n",
    "                w[f][order]\n",
    "                for w, f, order in zip(self.weights, features, self.symmetry_types)\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "    def predict(self, board):\n",
    "        # TODO: Predict the policy (probability distribution over actions) given the board state.\n",
    "        features = self.get_feature(board)\n",
    "        action_values = self.get_action_values(features)\n",
    "        return action_values\n",
    "        # value_sum = np.sum(action_values)\n",
    "\n",
    "        #  if value_sum == 0:\n",
    "        #    return np.full(4, 1 / 4)\n",
    "\n",
    "        action_dist = action_values\n",
    "        # print(f\"{action_dist=}\")\n",
    "        return action_dist\n",
    "\n",
    "    def update(self, board, target_distribution, alpha=0.1):\n",
    "        # TODO: Update policy based on the target distribution.\n",
    "        features = self.get_feature(board)\n",
    "        # delta = target_distribution - self.predict(board)\n",
    "        # print(f\"{target_distribution=}\")\n",
    "        # print(f\"{delta=}\")\n",
    "        # assert len(self.weights) == len(features) == len(self.rsymmetry_types)\n",
    "        # print(f\"before {self.predict(board)}\")\n",
    "        for w, f, order, rorder in zip(\n",
    "            self.weights, features, self.symmetry_types, self.rsymmetry_types\n",
    "        ):\n",
    "            # print(f\"change {alpha * delta[rorder]}\")\n",
    "            delta = np.sign(target_distribution - w[f][order]) * alpha\n",
    "            n_pos = np.sum(delta > 0)\n",
    "            n_neg = 4 - n_pos\n",
    "            for i in range(4):\n",
    "                if delta[i] > 0:\n",
    "                    delta[i] *= n_neg / n_pos\n",
    "\n",
    "            w[f] += alpha * delta[rorder]\n",
    "            # print(f\"weight {w[f]}\")\n",
    "        # print(f\"after {self.predict(board)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:11:03.582333Z",
     "iopub.status.busy": "2025-04-09T16:11:03.582200Z",
     "iopub.status.idle": "2025-04-09T16:11:03.585722Z",
     "shell.execute_reply": "2025-04-09T16:11:03.585388Z"
    },
    "id": "VGimbtmm7LKM"
   },
   "outputs": [],
   "source": [
    "def self_play_training_policy_with_td_mcts(\n",
    "    env, td_mcts, policy_approximator, num_episodes=50\n",
    "):\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Create the root node for the TD-MCTS tree\n",
    "            root = TD_MCTS_Node(state, env.score)\n",
    "\n",
    "            # Run multiple simulations to build the MCTS search tree\n",
    "            for _ in range(td_mcts.iterations):\n",
    "                td_mcts.run_simulation(root)\n",
    "\n",
    "            best_action, target_distribution = td_mcts.best_action_distribution(root)\n",
    "\n",
    "            # TODO: Update the NTuple Policy Approximator using the MCTS action distribution\n",
    "            # Here, we use the MCTS result directly as the label to update the policy\n",
    "            policy_approximator.update(state, target_distribution)\n",
    "\n",
    "            # Execute the selected action in the real environment\n",
    "            state, reward, done, _ = env.step(best_action)\n",
    "\n",
    "        print(f\"Episode {episode+1}/{num_episodes} finished, final score: {env.score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:11:03.587056Z",
     "iopub.status.busy": "2025-04-09T16:11:03.586925Z",
     "iopub.status.idle": "2025-04-09T16:32:57.458014Z",
     "shell.execute_reply": "2025-04-09T16:32:57.457568Z"
    },
    "id": "QEsTDX6K7FuU"
   },
   "outputs": [],
   "source": [
    "env = Game2048Env()\n",
    "\n",
    "# TODO: Define your own pattern\n",
    "# fmt:off\n",
    "patterns = [\n",
    "    [\n",
    "        [1, 1, 1, 1],\n",
    "        [1, 1, 0, 0],\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 0, 0, 0]\n",
    "    ],\n",
    "    [\n",
    "        [0, 0, 0, 0],\n",
    "        [1, 1, 1, 1],\n",
    "        [1, 1, 0, 0],\n",
    "        [0, 0, 0, 0]\n",
    "    ],\n",
    "    \n",
    "    [\n",
    "        [1, 1, 1, 0],\n",
    "        [1, 1, 1, 0],\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 0, 0, 0]\n",
    "    ],\n",
    "    [\n",
    "        [0, 0, 0, 0],\n",
    "        [1, 1, 1, 0],\n",
    "        [1, 1, 1, 0],\n",
    "        [0, 0, 0, 0]\n",
    "    ],\n",
    "]\n",
    "\"\"\"\n",
    "lines = [\n",
    "    [\n",
    "        [1, 1, 1, 1],\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 0, 0, 0]\n",
    "    ],\n",
    "    [\n",
    "        [0, 0, 0, 0],\n",
    "        [1, 1, 1, 1],\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 0, 0, 0]\n",
    "    ],\n",
    "    [\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 0, 0, 0],\n",
    "        [1, 1, 1, 1],\n",
    "        [0, 0, 0, 0]\n",
    "    ],\n",
    "    [\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 0, 0, 0],\n",
    "        [1, 1, 1, 1],\n",
    "    ],\n",
    "]\n",
    "lines = [np.array(l) for l in lines]\n",
    "lines += [np.rot90(l, k=1) for l in lines]\n",
    "\n",
    "squares = [\n",
    "    [\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 1, 0, 0],\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 0, 0, 0],\n",
    "    ],\n",
    "    [\n",
    "        [0, 1, 1, 0],\n",
    "        [0, 1, 1, 0],\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 0, 0, 0],\n",
    "    ]\n",
    "]\n",
    "center_square = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 1, 1, 0],\n",
    "    [0, 1, 1, 0],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "squares = [np.rot90(square, k=k) for square in squares for k in range(4) ]\n",
    "squares.append(center_square)\n",
    "patterns =  lines + squares\n",
    "\"\"\"\n",
    "# fmt:on\n",
    "patterns = [np.array(l) == 1 for l in patterns]\n",
    "\n",
    "# approximator = NTupleApproximator(board_size=4, patterns=patterns)\n",
    "\n",
    "policy_approximator = PolicyApproximator(board_size=4, patterns=patterns)\n",
    "# print(policy_approximator.rsymmetry_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training more works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/5 finished, final score: 10716\n",
      "Episode 2/5 finished, final score: 11848\n",
      "Episode 3/5 finished, final score: 10292\n",
      "Episode 4/5 finished, final score: 11328\n",
      "Episode 5/5 finished, final score: 10996\n"
     ]
    }
   ],
   "source": [
    "td_mcts = TD_MCTS(\n",
    "    env,\n",
    "    approximator,\n",
    "    iterations=50,\n",
    "    exploration_constant=1.41,\n",
    "    rollout_depth=10,\n",
    "    gamma=0.99,\n",
    ")\n",
    "self_play_training_policy_with_td_mcts(\n",
    "    env, td_mcts, policy_approximator, num_episodes=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibRMhtq-J4qs"
   },
   "source": [
    "### **Policy Evaluation: Comparing Policy-Based and Random Agents**\n",
    "\n",
    "This cell **evaluates the performance of the learned policy approximator** by running multiple games and comparing its average score to a random agent.\n",
    "\n",
    "- The **policy-based agent** selects actions using the trained policy approximator, without any MCTS search.\n",
    "- The **random agent** selects actions uniformly at random as a baseline for comparison.\n",
    "- Each agent plays **10 games**, and their **average score and standard deviation** are recorded.\n",
    "\n",
    "By comparing the results, we can assess whether the policy has successfully learned a meaningful strategy.\n",
    "\n",
    "- If the **policy consistently outperforms the random agent**, it indicates that training has been effective.\n",
    "- If the scores are similar, the policy may not have learned useful patterns and may require further training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:32:57.459603Z",
     "iopub.status.busy": "2025-04-09T16:32:57.459460Z",
     "iopub.status.idle": "2025-04-09T16:32:59.628008Z",
     "shell.execute_reply": "2025-04-09T16:32:59.627464Z"
    },
    "id": "3MtVf6-rJHWJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy-based Agent - Avg Score: 2409.20, Std Dev: 1571.95\n",
      "Random Agent - Avg Score: 837.20, Std Dev: 579.91\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def evaluate_policy(env, policy_approximator, num_games=10):\n",
    "    scores = []\n",
    "    env.render()\n",
    "    for _ in range(num_games):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            # TODO: play with your policy approximator\n",
    "            action_dist = policy_approximator.predict(state)\n",
    "            root = TD_MCTS_Node(state, env.score)\n",
    "\n",
    "            # Run multiple simulations to build the MCTS search tree\n",
    "            for _ in range(td_mcts.iterations):\n",
    "                td_mcts.run_simulation(root)\n",
    "\n",
    "            target_action, target_distribution = td_mcts.best_action_distribution(root)\n",
    "\n",
    "            legal_moves = [a for a in range(4) if env.is_move_legal(a)]\n",
    "\n",
    "            best_action = max(legal_moves, key=lambda a: action_dist[a])\n",
    "            # print(action_dist, target_distribution, best_action, target_action)\n",
    "\n",
    "            state, reward, done, _ = env.step(best_action)\n",
    "            env.render(action=best_action)\n",
    "        scores.append(env.score)\n",
    "\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "\n",
    "def evaluate_random(env, num_games=10):\n",
    "    scores = []\n",
    "    env.render()\n",
    "    for _ in range(num_games):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            legal_moves = [a for a in range(4) if env.is_move_legal(a)]\n",
    "            if not legal_moves:\n",
    "                break\n",
    "            action = random.choice(legal_moves)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            env.render(action=action)\n",
    "        scores.append(env.score)\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "\n",
    "num_games = 10\n",
    "policy_mean, policy_std = evaluate_policy(env, policy_approximator, num_games)\n",
    "random_mean, random_std = evaluate_random(env, num_games)\n",
    "\n",
    "\n",
    "print(f\"Policy-based Agent - Avg Score: {policy_mean:.2f}, Std Dev: {policy_std:.2f}\")\n",
    "print(f\"Random Agent - Avg Score: {random_mean:.2f}, Std Dev: {random_std:.2f}\")\n",
    "\n",
    "# Visualization: Compare Policy vs. Random Agent\n",
    "labels = [\"Policy-based Agent\", \"Random Agent\"]\n",
    "means = [policy_mean, random_mean]\n",
    "std_devs = [policy_std, random_std]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, means, yerr=std_devs, capsize=10, color=[\"blue\", \"red\"])\n",
    "plt.ylabel(\"Average Score\")\n",
    "plt.title(\"Policy vs. Random Agent Performance\")\n",
    "plt.ylim(0, max(means) + max(std_devs) * 1.2)\n",
    "\n",
    "\n",
    "for i, v in enumerate(means):\n",
    "    plt.text(i, v + max(std_devs) * 0.1, f\"{v:.2f}\", ha=\"center\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWLf-ZxSdYNc"
   },
   "source": [
    "**Question:**\n",
    "\n",
    "- Provide a graph comparing your policy agent and random agent performance.\n",
    "\n",
    "- What is your tuple design?\n",
    "\n",
    "- After implementing the value and policy approximators, what is the main difference between these two?\n",
    "  For example, what aspects of training require more attention for the policy approximator compared to the value approximator?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- graph see above\n",
    "\n",
    "- (Same as the previous question) Four 6-tuple from paper.\n",
    "\n",
    "```\n",
    "[\n",
    "\t[1, 1, 1, 1],\n",
    "\t[1, 1, 0, 0],\n",
    "\t[0, 0, 0, 0],\n",
    "\t[0, 0, 0, 0]\n",
    "],\n",
    "[\n",
    "\t[0, 0, 0, 0],\n",
    "\t[1, 1, 1, 1],\n",
    "\t[1, 1, 0, 0],\n",
    "\t[0, 0, 0, 0]\n",
    "],\n",
    "\n",
    "[\n",
    "\t[1, 1, 1, 0],\n",
    "\t[1, 1, 1, 0],\n",
    "\t[0, 0, 0, 0],\n",
    "\t[0, 0, 0, 0]\n",
    "],\n",
    "[\n",
    "\t[0, 0, 0, 0],\n",
    "\t[1, 1, 1, 0],\n",
    "\t[1, 1, 1, 0],\n",
    "\t[0, 0, 0, 0]\n",
    "]\n",
    "```\n",
    "\n",
    "- The main difference is that the policy approximator records the values for making decision at each state while the value approximator relies on the simulated next state. To maintain the additional information of policy approximator, one has to record the transformation of the flipped symmetries so that one can distinguish their action directions to use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X05mxnce_CYk"
   },
   "source": [
    "## **PUCT-MCTS: Combining MCTS with Policy and Value Approximators**\n",
    "\n",
    "### **What We Are Doing**\n",
    "\n",
    "- We **integrate a trained policy approximator into MCTS** using the **PUCT formula**.\n",
    "- This **improves exploration efficiency** by guiding MCTS with **learned action priors**.\n",
    "- Instead of selecting moves **only by visit counts**, MCTS now considers **both value (Q) and policy priors (P)**.\n",
    "\n",
    "### **Key Modifications**\n",
    "\n",
    "1. **Selection uses the PUCT formula:**\n",
    "   $Q(s, a) + c_{puct} \\cdot P(s, a) \\cdot \\frac{\\sqrt{N(s)}}{1 + N(s, a)}$\n",
    "\n",
    "   - $Q(s, a)$: Average action value.\n",
    "   - $P(s, a)$: Prior probability from the **trained policy approximator**.\n",
    "   - $ N(s) $, $N(s, a)$ : Visit counts.\n",
    "   - $c_{puct}$ : Controls exploration.\n",
    "\n",
    "2. **Expansion phase now sets priors using the policy approximator.**\n",
    "3. **Rollout phase still uses the value approximator but is now optional.**\n",
    "4. **MCTS learns from past searches, improving decision-making over time.**\n",
    "\n",
    "### **Why This Works**\n",
    "\n",
    "- **Pure MCTS** spends too much time **exploring all moves equally**.\n",
    "- **PUCT guides search** using **pre-learned probabilities**, reducing unnecessary exploration.\n",
    "- This approach is **used in AlphaZero**, enabling **faster and stronger AI decision-making**.\n",
    "\n",
    "üöÄ **This method makes MCTS much more efficient and effective!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:32:59.629670Z",
     "iopub.status.busy": "2025-04-09T16:32:59.629524Z",
     "iopub.status.idle": "2025-04-09T16:32:59.641688Z",
     "shell.execute_reply": "2025-04-09T16:32:59.641195Z"
    },
    "id": "lcLe8tLQr_SZ"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PUCTNode:\n",
    "    def __init__(self, state, score, parent=None, action=None, prior=0.0):\n",
    "        self.state = state\n",
    "        self.score = score\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.prior = prior\n",
    "        self.children = {}\n",
    "        self.visits = 0\n",
    "        self.total_reward = 0.0\n",
    "        self.untried_actions = [a for a in range(4) if env.is_move_legal(a)]\n",
    "\n",
    "    def fully_expanded(self):\n",
    "        return len(self.untried_actions) == 0\n",
    "\n",
    "\n",
    "class MCTS_PUCT:\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        value_approximator,\n",
    "        policy_approximator,\n",
    "        iterations=500,\n",
    "        c_puct=1.41,\n",
    "        rollout_depth=10,\n",
    "        gamma=0.99,\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.value_approximator = value_approximator\n",
    "        self.policy_approximator = policy_approximator\n",
    "        self.iterations = iterations\n",
    "        self.c_puct = c_puct\n",
    "        self.rollout_depth = rollout_depth\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def create_env_from_state(self, state, score):\n",
    "        \"\"\"Creates a deep copy of the environment to simulate a given state.\"\"\"\n",
    "        # new_env = Game2048Env()\n",
    "        # new_env.reset(state, score)\n",
    "        # return new_env\n",
    "        new_env = copy.deepcopy(self.env)\n",
    "        new_env.board = state.copy()\n",
    "        new_env.score = score\n",
    "        return new_env\n",
    "\n",
    "    def select_child(self, node):\n",
    "        # TODO: Select the best child using the PUCT formula:\n",
    "        # PUCT(s,a) = Q(s,a) + c_puct * P(s,a) * sqrt(N(s)) / (1 + N(s,a))\n",
    "        # where Q(s,a) = child.total_reward / child.visits.\n",
    "\n",
    "        if len(node.untried_actions) != 0:\n",
    "            return node.children[node.untried_actions[0]]\n",
    "        else:\n",
    "            puct_max = -np.inf\n",
    "            child_max = None\n",
    "            for action, child in node.children.items():\n",
    "                puct_value = child.total_reward / child.visits + self.c_puct * np.sqrt(\n",
    "                    np.log(node.visits) / (1 + child.visits)\n",
    "                )\n",
    "                if puct_value > puct_max:\n",
    "                    puct_max = puct_value\n",
    "                    child_max = child\n",
    "\n",
    "            return child_max\n",
    "\n",
    "    def rollout(self, sim_env, depth):\n",
    "        # TODO: Perform a random rollout until reaching the maximum depth or a terminal state.\n",
    "        # TODO: Use the approximator to evaluate the final state.\n",
    "        state = sim_env.board.copy()\n",
    "        while not sim_env.is_game_over() and depth > 0:\n",
    "            legal_moves = [a for a in range(4) if sim_env.is_move_legal(a)]\n",
    "            if len(legal_moves) == 0:\n",
    "                break\n",
    "            action = random.choice(legal_moves)\n",
    "            state, _, done, _ = sim_env.step(action)\n",
    "            depth -= 1\n",
    "\n",
    "        return sim_env.score + self.value_approximator.value(state)\n",
    "\n",
    "        # Note: It's not necessary to perform rollouts if the value approximator is accurate.\n",
    "        value_est = self.value_approximator.value(sim_env.board)\n",
    "        return value_est\n",
    "\n",
    "    def backpropagate(self, node, reward):\n",
    "        # TODO: Propagate the reward up the tree, updating visit counts and total rewards.\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.total_reward += reward\n",
    "            node = node.parent\n",
    "\n",
    "    def run_simulation(self, root):\n",
    "        node = root\n",
    "\n",
    "        # TODO: Selection phase: traverse the tree until reaching an expandable node.\n",
    "        while node.fully_expanded():\n",
    "            child = self.select_child(node)\n",
    "            if child is None:\n",
    "                break\n",
    "            node = child\n",
    "\n",
    "        sim_env = self.create_env_from_state(node.state, node.score)\n",
    "        # TODO: Expansion phase: if the node is not terminal, expand one untried action.\n",
    "        if len(node.untried_actions) != 0:\n",
    "            action = random.choice(node.untried_actions)\n",
    "            node.untried_actions.remove(action)\n",
    "            state, score, done, _ = sim_env.step(action)\n",
    "            expanded_node = PUCTNode(state, score)\n",
    "            node.children[action] = expanded_node\n",
    "            expanded_node.parent = node\n",
    "            node = expanded_node\n",
    "\n",
    "        # Rollout phase: simulate random moves from the expanded node.\n",
    "        rollout_reward = self.rollout(sim_env, self.rollout_depth)\n",
    "        # Backpropagation phase: update the tree with the obtained reward.\n",
    "        self.backpropagate(node, rollout_reward)\n",
    "\n",
    "    def best_action_distribution(self, root):\n",
    "        total_visits = sum(child.visits for child in root.children.values())\n",
    "        distribution = np.zeros(4)\n",
    "        best_visits = -1\n",
    "        best_action = None\n",
    "        for action, child in root.children.items():\n",
    "            distribution[action] = (\n",
    "                child.visits / total_visits if total_visits > 0 else 0\n",
    "            )\n",
    "            if child.visits > best_visits:\n",
    "                best_visits = child.visits\n",
    "                best_action = action\n",
    "        return best_action, distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UT5AYCE0gtOa"
   },
   "source": [
    "**Question:**  \n",
    "Implementation details of your **PUCT-MCTS**.  \n",
    "Since there are many differences between **PUCT-MCTS** and **UCT-MCTS** (policy, value), please provide a detailed explanation of your implementation.  \n",
    "For example, describe the differences in **selection, expansion, or other relevant aspects**.\n",
    "\n",
    "- **_Note: Ensure that your explanation matches the actual implementation, or points will be deducted._**\n",
    "\n",
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LA6mnQX9ALbt"
   },
   "source": [
    "### **Playing 2048 Using PUCT-MCTS with TD-Learned Approximators**\n",
    "\n",
    "- We play **2048 using PUCT-MCTS**, which combines **Monte Carlo Tree Search** with:\n",
    "- **A value approximator** trained via **TD-learning** (N-Tuple function).\n",
    "- **A policy approximator** trained via **self-play with MCTS**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:32:59.643237Z",
     "iopub.status.busy": "2025-04-09T16:32:59.643098Z",
     "iopub.status.idle": "2025-04-09T16:33:07.046956Z",
     "shell.execute_reply": "2025-04-09T16:33:07.046396Z"
    },
    "id": "1tHZn3KS74ow"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUCT selected action: 0 with visit distribution: [0.68 0.02 0.02 0.28]\n",
      "PUCT selected action: 2 with visit distribution: [0.46 0.02 0.5  0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.04 0.92 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.14 0.8  0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.82 0.16 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.16 0.82 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.1  0.1  0.76]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.1  0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.04 0.04 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.36 0.26 0.34]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.34 0.04 0.56 0.06]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.86 0.1 ]\n",
      "PUCT selected action: 3 with visit distribution: [0.46 0.02 0.02 0.5 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.   0.06]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.82 0.02 0.12]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.94 0.04]\n",
      "PUCT selected action: 3 with visit distribution: [0.18 0.   0.02 0.8 ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.22 0.74]\n",
      "PUCT selected action: 0 with visit distribution: [0.66 0.3  0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.2  0.02 0.76 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.7  0.1  0.04 0.16]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.04 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.88 0.08]\n",
      "PUCT selected action: 0 with visit distribution: [0.72 0.26 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.78 0.18]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.76 0.2  0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.06 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.12 0.02 0.84]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.38 0.02 0.58]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.98 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.04 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.12 0.42 0.38 0.08]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.9  0.06]\n",
      "PUCT selected action: 2 with visit distribution: [0.26 0.16 0.56 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.9 0.  0.  0.1]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.06 0.04 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.08 0.7  0.2 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.48 0.02 0.46]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.1  0.02 0.88 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.06 0.02 0.36 0.56]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.24 0.02 0.08 0.66]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.68 0.28]\n",
      "PUCT selected action: 0 with visit distribution: [0.6  0.08 0.3  0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.86 0.1  0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.18 0.78 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.24 0.02 0.72 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.08 0.02 0.02 0.88]\n",
      "PUCT selected action: 1 with visit distribution: [0.1  0.82 0.04 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.72 0.04 0.22 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.7  0.26 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.82 0.14 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.86 0.1  0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.16 0.12 0.6  0.12]\n",
      "PUCT selected action: 0 with visit distribution: [0.54 0.42 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.12 0.02 0.86]\n",
      "PUCT selected action: 0 with visit distribution: [0.58 0.4  0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.98 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.74 0.02 0.02 0.22]\n",
      "PUCT selected action: 3 with visit distribution: [0.06 0.02 0.02 0.9 ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.24 0.14 0.6 ]\n",
      "PUCT selected action: 3 with visit distribution: [0.46 0.02 0.06 0.46]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.52 0.44]\n",
      "PUCT selected action: 3 with visit distribution: [0.06 0.02 0.02 0.9 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.06 0.92 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.62 0.32 0.04 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.06 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.18 0.02 0.08 0.72]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.48 0.08 0.42 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.  0.6 0.4 0. ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.04 0.04]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.1  0.86 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.   0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.8  0.04 0.02 0.14]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.16 0.16 0.66]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.78 0.18 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.08 0.02 0.88 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.86 0.1 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.06 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.94 0.06 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.   0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.04 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.98 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.06 0.02 0.7  0.22]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.02 0.02 0.08]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.26 0.68]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.04 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.64 0.04 0.02 0.3 ]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.92 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.08 0.04 0.88]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.12 0.84]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.92 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.06 0.88]\n",
      "PUCT selected action: 0 with visit distribution: [0.68 0.02 0.02 0.28]\n",
      "PUCT selected action: 1 with visit distribution: [0.1  0.86 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.76 0.16 0.06]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.08 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.14 0.8 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.24 0.72 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.78 0.06 0.14 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.74 0.1  0.16 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.98 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.02 0.02 0.1 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.88 0.08]\n",
      "PUCT selected action: 3 with visit distribution: [0.06 0.06 0.04 0.84]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.12 0.   0.86 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "PUCT selected action: 2 with visit distribution: [0.08 0.04 0.86 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.   0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.08 0.88 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.   0.98]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.06 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.12 0.04 0.82 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.86 0.04 0.08]\n",
      "PUCT selected action: 0 with visit distribution: [0.64 0.02 0.24 0.1 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.08 0.   0.04 0.88]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.94 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.04 0.9 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.98 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.04 0.02 0.9 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.08 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.24 0.74 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.06 0.92 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.04 0.92]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.02 0.02 0.08]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.86 0.04 0.1 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.04 0.88 0.08]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.02 0.   0.1 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.44 0.38 0.18 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.68 0.26]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.08 0.   0.06]\n",
      "PUCT selected action: 2 with visit distribution: [0.06 0.3  0.56 0.08]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.94 0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.04 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.94 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.12 0.82 0.06 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.08 0.88]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.98 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.92 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.98 0.   0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.74 0.26]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.52 0.02 0.46]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.   0.02 0.98]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.04 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.06 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.   0.06 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.   0.   0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.1  0.86]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.1  0.86 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.72 0.06 0.1  0.12]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.08 0.9  0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.02 0.02 0.1 ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.06 0.9 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.34 0.64 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.08 0.04 0.38 0.5 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.94 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.24 0.34 0.42]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.04 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.04 0.04 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.   0.98]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.04 0.04 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.02 0.1  0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.   0.04 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.   0.98]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.02 0.06]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.   0.1  0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.   0.02 0.98]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.   0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.12 0.86 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.04 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.12 0.1  0.02 0.76]\n",
      "PUCT selected action: 2 with visit distribution: [0.08 0.   0.9  0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.18 0.78 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.8  0.16 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.82 0.14]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.88 0.06 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.04 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.06 0.04 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.02 0.1  0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.06 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.   0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.9  0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.   0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.04 0.02 0.06]\n",
      "PUCT selected action: 0 with visit distribution: [0.84 0.04 0.1  0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.08 0.9  0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.74 0.22 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.1  0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.   0.02 0.98]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.16 0.8  0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "Game over, final score: 5532\n"
     ]
    }
   ],
   "source": [
    "env = Game2048Env()\n",
    "\n",
    "# Reset the environment and render the initial state\n",
    "state = env.reset()\n",
    "env.render()\n",
    "\n",
    "mcts_puct = MCTS_PUCT(\n",
    "    env,\n",
    "    value_approximator=approximator,\n",
    "    policy_approximator=policy_approximator,\n",
    "    iterations=50,\n",
    "    c_puct=1.41,\n",
    "    rollout_depth=10,\n",
    "    gamma=0.99,\n",
    ")\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    root = PUCTNode(state, env.score)\n",
    "    for _ in range(mcts_puct.iterations):\n",
    "        mcts_puct.run_simulation(root)\n",
    "\n",
    "    best_act, visit_distribution = mcts_puct.best_action_distribution(root)\n",
    "    print(\n",
    "        \"PUCT selected action:\",\n",
    "        best_act,\n",
    "        \"with visit distribution:\",\n",
    "        visit_distribution,\n",
    "    )\n",
    "\n",
    "    state, reward, done, _ = env.step(best_act)\n",
    "    env.render(action=best_act)\n",
    "\n",
    "print(\"Game over, final score:\", env.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElchFNaaDx8W"
   },
   "source": [
    "## **Self-Play Training for PUCT-MCTS (Like AlphaZero, But Without Neural Networks!)**\n",
    "\n",
    "### **What We Are Doing**\n",
    "\n",
    "- We are implementing a **self-play reinforcement learning framework** similar to **AlphaZero**.\n",
    "- Instead of using **deep neural networks**, we use:\n",
    "  - **A policy approximator (table-based)**\n",
    "  - **A value approximator (N-Tuple function)**\n",
    "  - **Monte Carlo Tree Search with PUCT (MCTS-PUCT)**\n",
    "- This allows **efficient training** without requiring **GPU-heavy deep learning models**.\n",
    "\n",
    "### **Why This Is Like AlphaZero**\n",
    "\n",
    "1. **Self-play** is used to **train both policy & value approximators**.\n",
    "2. **MCTS guides exploration**, and the **policy learns from MCTS visit counts**.\n",
    "3. **The value function is updated** based on MCTS rollouts.\n",
    "4. **No pre-training is required**‚Äîthe agent **improves purely through self-play**.  \n",
    "   **(Note: Although pre-training is not required, we use a pre-trained value table to accelerate learning.)**\n",
    "\n",
    "### **Why This Works Without Neural Networks**\n",
    "\n",
    "- **N-Tuple approximators** efficiently estimate state values.\n",
    "- **Policy tables** generalize well in smaller action spaces (like 2048).\n",
    "- **PUCT-MCTS improves search efficiency**, making deep networks unnecessary.\n",
    "\n",
    "üöÄ **This is a lightweight, efficient version of AlphaZero, optimized for 2048!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:33:07.048566Z",
     "iopub.status.busy": "2025-04-09T16:33:07.048418Z",
     "iopub.status.idle": "2025-04-09T16:33:07.053361Z",
     "shell.execute_reply": "2025-04-09T16:33:07.052876Z"
    },
    "id": "IOH3peRip2lT"
   },
   "outputs": [],
   "source": [
    "def self_play_training_policy_value(\n",
    "    env,\n",
    "    mcts_puct,\n",
    "    policy_approximator,\n",
    "    value_approximator,\n",
    "    num_episodes=50,\n",
    "    value_lr=0.01,\n",
    "):\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        previous_score = 0\n",
    "\n",
    "        while not done:\n",
    "            # Create the root node for the MCTS-PUCT tree\n",
    "            root = PUCTNode(state, env.score)\n",
    "\n",
    "            # Run multiple simulations to build the MCTS search tree\n",
    "            for _ in range(mcts_puct.iterations):\n",
    "                mcts_puct.run_simulation(root)\n",
    "\n",
    "            best_action, target_distribution = td_mcts.best_action_distribution(root)\n",
    "            # TODO: Update the NTuple Policy Approximator using the MCTS action distribution\n",
    "            policy_approximator.update(state, target_distribution)\n",
    "            # TODO: Calculate the TD error for the value approximator and update your approximator\n",
    "\n",
    "            # Execute the selected action in the real environment\n",
    "            next_state, new_score, done, _ = env.step(best_action)\n",
    "\n",
    "            incremental_reward = new_score - previous_score\n",
    "\n",
    "            # gamma = 0.99\n",
    "            delta = (\n",
    "                incremental_reward\n",
    "                + approximator.value(next_state)\n",
    "                - approximator.value(state)\n",
    "            )\n",
    "            value_approximator.update(state, delta, value_lr)\n",
    "\n",
    "            previous_score = new_score\n",
    "            state = next_state\n",
    "            # print(state)\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode + 1}/{num_episodes} finished, final score: {env.score}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:33:07.054789Z",
     "iopub.status.busy": "2025-04-09T16:33:07.054650Z",
     "iopub.status.idle": "2025-04-09T16:34:42.951824Z",
     "shell.execute_reply": "2025-04-09T16:34:42.951396Z"
    },
    "id": "mraHor9Y8Myj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/10 finished, final score: 5256\n",
      "Episode 2/10 finished, final score: 5256\n",
      "Episode 3/10 finished, final score: 6408\n",
      "Episode 4/10 finished, final score: 7144\n",
      "Episode 5/10 finished, final score: 4684\n",
      "Episode 6/10 finished, final score: 3128\n",
      "Episode 7/10 finished, final score: 15872\n",
      "Episode 8/10 finished, final score: 7152\n",
      "Episode 9/10 finished, final score: 5376\n",
      "Episode 10/10 finished, final score: 5416\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the PUCT MCTS object using the pre-trained NTuple-based approximators.\n",
    "\n",
    "mcts_puct = MCTS_PUCT(\n",
    "    env,\n",
    "    value_approximator=approximator,\n",
    "    policy_approximator=policy_approximator,\n",
    "    iterations=50,\n",
    "    c_puct=1.41,\n",
    "    rollout_depth=10,\n",
    "    gamma=0.99,\n",
    ")\n",
    "\n",
    "# Run the self-play training loop to further update both the policy and value approximators.\n",
    "self_play_training_policy_value(\n",
    "    env, mcts_puct, policy_approximator, approximator, num_episodes=10, value_lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgvlXE12i_rC"
   },
   "source": [
    "**Question:**\n",
    "\n",
    "- Provide a **graph showing training steps vs. score progression** to illustrate learning performance.\n",
    "\n",
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFTO0YOOFRZl"
   },
   "source": [
    "### **Playing 2048 Using PUCT-MCTS with Trained Approximators**\n",
    "\n",
    "- Now that we have **trained the policy and value approximators** through self-play, we **test them in actual gameplay**.\n",
    "- The agent will play **2048 using PUCT-MCTS**, making **smarter, more efficient decisions**.\n",
    "- This is the **final step**, where we evaluate how well our training has improved the agent.\n",
    "\n",
    "üöÄ **Now, let's see how well our trained agent plays 2048!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:34:42.953553Z",
     "iopub.status.busy": "2025-04-09T16:34:42.953335Z",
     "iopub.status.idle": "2025-04-09T16:34:51.120114Z",
     "shell.execute_reply": "2025-04-09T16:34:51.119562Z"
    },
    "id": "zD0PYVB19QTd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.16 0.08 0.74 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.8  0.02 0.16]\n",
      "PUCT selected action: 0 with visit distribution: [0.68 0.22 0.08 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.9  0.04]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.04 0.08 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.06 0.64 0.3 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.54 0.42 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.   0.06]\n",
      "PUCT selected action: 1 with visit distribution: [0.08 0.62 0.02 0.28]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.92 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.14 0.8  0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.86 0.06 0.06]\n",
      "PUCT selected action: 3 with visit distribution: [0.28 0.04 0.08 0.6 ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.06 0.88]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.92 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.04 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.14 0.16 0.7 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.06 0.02 0.9  0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.04 0.08 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.06 0.54 0.38]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.08 0.04 0.02 0.86]\n",
      "PUCT selected action: 0 with visit distribution: [0.68 0.24 0.04 0.04]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.04 0.92]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.06 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.18 0.76 0.04 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.1 0.  0.9 0. ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.   0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.86 0.1  0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.82 0.02 0.14]\n",
      "PUCT selected action: 3 with visit distribution: [0.08 0.02 0.04 0.86]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.02 0.02 0.1 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.28 0.12 0.38 0.22]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.86 0.04 0.08]\n",
      "PUCT selected action: 2 with visit distribution: [0.3  0.02 0.58 0.1 ]\n",
      "PUCT selected action: 1 with visit distribution: [0.24 0.74 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.02 0.08 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.06 0.56 0.38]\n",
      "PUCT selected action: 3 with visit distribution: [0.1  0.02 0.02 0.86]\n",
      "PUCT selected action: 0 with visit distribution: [0.78 0.02 0.16 0.04]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.68 0.06 0.02 0.24]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.18 0.02 0.1  0.7 ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.08 0.02 0.88]\n",
      "PUCT selected action: 2 with visit distribution: [0.18 0.02 0.78 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.02 0.04 0.06]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.2  0.02 0.76]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.88 0.04 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.   0.76 0.2 ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.06 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.84 0.1  0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.04 0.9  0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.84 0.   0.14]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.78 0.02 0.02 0.18]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.72 0.24]\n",
      "PUCT selected action: 3 with visit distribution: [0.36 0.04 0.06 0.54]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.06 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.14 0.84 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.04 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.7  0.08 0.02 0.2 ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.06 0.02 0.88 0.04]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.9  0.06 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.04 0.9 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.06 0.9  0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.   0.98]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.1  0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.08 0.02 0.86 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.06 0.   0.06]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.04 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.1  0.02 0.02 0.86]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.9  0.06]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.88 0.08 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.   0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.9  0.06 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.9  0.06]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.92 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.98 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.12 0.   0.86 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.02 0.12 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.84 0.08 0.08]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.16 0.82]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.06 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.04 0.9  0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.64 0.02 0.28]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.9  0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.24 0.74 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.9  0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0. 1. 0. 0.]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.12 0.86]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.74 0.12 0.12 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.92 0.06]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.88 0.08 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.04 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 3 with visit distribution: [0.1  0.02 0.02 0.86]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.   0.   0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.88 0.02 0.08]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.   0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.04 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.08 0.02 0.88 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.88 0.04 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.   0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.   0.14 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.26 0.72]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.08 0.88 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.06 0.02 0.9  0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.   0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.04 0.9  0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.   0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.08 0.88 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.36 0.6 ]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.92 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.1  0.86 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.76 0.   0.2 ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.18 0.06 0.74 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.06 0.88]\n",
      "PUCT selected action: 1 with visit distribution: [0.08 0.9  0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.1  0.86 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.1  0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.82 0.16 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.98 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.94 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.   0.02 0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.82 0.14 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.9  0.04 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.06 0.9  0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.06 0.1  0.82 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.82 0.14 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.04 0.72 0.22]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.24 0.72 0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.12 0.84]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.9  0.06]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.98 0.   0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.04 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.94 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.   0.04 0.92]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.06 0.92 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.98 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.   0.   0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.9  0.06 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.94 0.   0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.08 0.   0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.04 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.04 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.9  0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.94 0.06]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.3  0.   0.02 0.68]\n",
      "PUCT selected action: 2 with visit distribution: [0.06 0.04 0.88 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.84 0.12 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.3  0.64 0.06]\n",
      "PUCT selected action: 3 with visit distribution: [0.06 0.42 0.02 0.5 ]\n",
      "PUCT selected action: 1 with visit distribution: [0.28 0.7  0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.   0.02 0.08]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.02 0.08 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.9  0.08]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.08 0.88]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.   0.08 0.88]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.   0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.5  0.02 0.46]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.   0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.   0.98]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.84 0.   0.02 0.14]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.92 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.   0.02 0.12]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.06 0.02 0.88]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.04 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.98 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.06 0.9 ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.96 0.   0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.   0.02 0.98]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.   0.02 0.98]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.12 0.02 0.68 0.18]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.06 0.   0.02 0.92]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.98 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.   0.04]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.14 0.5  0.34 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.08 0.86 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.84 0.02 0.   0.14]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.02 0.02 0.1 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.28 0.14 0.56 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.06 0.02 0.9  0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.04 0.96 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.06 0.9 ]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.94 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.94 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.   0.02 0.12]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.82 0.02 0.16]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.82 0.02 0.14 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.1  0.86 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.94 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.1  0.86 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.94 0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.04 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0. 0. 1. 0.]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.04 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.12 0.06 0.78 0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.04 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.08 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.   0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.   0.   0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.16 0.8  0.04 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.84 0.12]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.04 0.   0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.04 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.96 0.   0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.02 0.04 0.06]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.64 0.02 0.32 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.02 0.08 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.02 0.06]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.78 0.04 0.02 0.16]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.   0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.04 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.08 0.   0.9 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.98 0.   0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.82 0.12]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.22 0.74 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.34 0.6  0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.   0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.42 0.54 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.16 0.76 0.06 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.28 0.66 0.06 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.08 0.8  0.12 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.1  0.88 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.2  0.74]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.98 0.   0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.04 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.1  0.86 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.86 0.02 0.1 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.08 0.06 0.84 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.06 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.1  0.88]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.14 0.1  0.74]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.06 0.02 0.02 0.9 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.92 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.06 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.94 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.86 0.12]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.06 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.76 0.02 0.2 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.04 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.88 0.08 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.94 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.04 0.92]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.06 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.98 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.12 0.86]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.   0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.2  0.1  0.68 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.08 0.   0.9  0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.9  0.04 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.06 0.9  0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.04 0.92 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.06 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.06 0.04 0.06 0.84]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.08 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.84 0.   0.14]\n",
      "PUCT selected action: 0 with visit distribution: [0.68 0.28 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.   0.98]\n",
      "PUCT selected action: 1 with visit distribution: [0.42 0.54 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.04 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.06 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.86 0.06 0.06]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.06 0.02 0.92]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.98 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.9  0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.1  0.16 0.72]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.4  0.06 0.54 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.04 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.1  0.8  0.08]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.   0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.   0.02 0.1 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.06 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.94 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.04 0.   0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.94 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.   0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "PUCT selected action: 0 with visit distribution: [0.84 0.08 0.06 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.06 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.08 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.   0.04 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.98 0.   0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.72 0.02 0.22 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.06 0.02 0.02 0.9 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.98 0.   0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.12 0.1  0.78]\n",
      "PUCT selected action: 1 with visit distribution: [0.16 0.82 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.6  0.36 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.04 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.9  0.06 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.   0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.   0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.94 0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.98 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.78 0.02 0.02 0.18]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.06 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.88 0.1 ]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.   0.1  0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.04 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.9  0.02 0.08]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.1  0.8  0.08]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.62 0.   0.36]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.04 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.08 0.04 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.84 0.   0.   0.16]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.06 0.9  0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.   0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.94 0.   0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.1 0.9 0.  0. ]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.92 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.92 0.04]\n",
      "PUCT selected action: 3 with visit distribution: [0.22 0.02 0.   0.76]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.98 0.   0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.04 0.9 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.7  0.18 0.02 0.1 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.08 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.88 0.02 0.06]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.02 0.04 0.08]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.04 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.06 0.   0.94 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.06 0.9 ]\n",
      "PUCT selected action: 1 with visit distribution: [0.16 0.82 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.08 0.9 ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.08 0.02 0.88]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.9  0.06]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.82 0.12 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.06 0.02 0.9  0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.9  0.06 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.12 0.84 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.   0.04]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.02 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.12 0.84 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.92 0.02 0.06]\n",
      "PUCT selected action: 2 with visit distribution: [0.06 0.   0.86 0.08]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.92 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.9  0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.06 0.92 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.   0.04]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.   0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.08 0.02 0.88 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.04 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.   0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.84 0.02 0.12 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.04 0.92 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.   0.04 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.04 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.82 0.14 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.   0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.86 0.02 0.1 ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.1  0.02 0.86]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.08 0.9 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.92 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.   0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.06 0.02 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.98 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.02 0.02 0.92]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.04 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.08 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.98 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.08 0.   0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.08 0.9  0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.9  0.02 0.08]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.22 0.76]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.9  0.02 0.06]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.86 0.02 0.06]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.02 0.94 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.12 0.02 0.86]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.9  0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.08 0.02 0.88]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.04 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.92 0.04 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.9  0.06 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.76 0.2 ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.06 0.02 0.9 ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.98 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.04 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.9  0.02 0.06]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.94 0.02 0.04]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.74 0.22 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.14 0.02 0.82]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.88 0.04 0.06 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.9  0.06 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.04 0.   0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.04 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.04 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.96 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.8  0.14 0.04 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.04 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.86 0.1  0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.06 0.   0.92 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.04 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.86 0.02 0.02 0.1 ]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.24 0.02 0.74]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.9  0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.1  0.84 0.02 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.82 0.14 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.86 0.12]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.02 0.96 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.9  0.02 0.02 0.06]\n",
      "PUCT selected action: 2 with visit distribution: [0.08 0.02 0.88 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.   0.98]\n",
      "PUCT selected action: 1 with visit distribution: [0.08 0.88 0.04 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.96 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.84 0.   0.14]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.06 0.92]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.14 0.02 0.82 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.02 0.   0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.   0.98]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.92 0.08 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.04 0.88 0.06]\n",
      "PUCT selected action: 2 with visit distribution: [0.1  0.1  0.78 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.92 0.02 0.   0.06]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.98 0.02 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.04 0.02 0.92]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.   0.02 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.96 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.   0.94 0.02 0.04]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.   0.02 0.96]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.86 0.12 0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.02 0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.1  0.86 0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.04 0.   0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.02 0.   0.98]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.   0.02 0.98]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.94 0.02 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.   0.02 0.98]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.9  0.06 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.06 0.76 0.02 0.16]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.08 0.06 0.84]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.08 0.9  0.  ]\n",
      "PUCT selected action: 1 with visit distribution: [0.28 0.72 0.   0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.   0.98 0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.84 0.16]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "PUCT selected action: 3 with visit distribution: [0.   0.   0.02 0.98]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.02 0.02 0.94]\n",
      "PUCT selected action: 0 with visit distribution: [0.62 0.02 0.36 0.  ]\n",
      "PUCT selected action: 3 with visit distribution: [0.04 0.06 0.02 0.88]\n",
      "PUCT selected action: 3 with visit distribution: [0.02 0.12 0.02 0.84]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.96 0.04]\n",
      "PUCT selected action: 0 with visit distribution: [0.94 0.02 0.02 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.98 0.   0.  ]\n",
      "PUCT selected action: 0 with visit distribution: [0.98 0.02 0.   0.  ]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 1 with visit distribution: [0.02 0.96 0.   0.02]\n",
      "PUCT selected action: 0 with visit distribution: [0.96 0.   0.02 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.12 0.84 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.02 0.02 0.94 0.02]\n",
      "PUCT selected action: 2 with visit distribution: [0.   0.   0.98 0.02]\n",
      "Game over! Final score: 16324, Highest tile: 1024\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "env.render()\n",
    "\n",
    "mcts_puct = MCTS_PUCT(\n",
    "    env,\n",
    "    value_approximator=approximator,\n",
    "    policy_approximator=policy_approximator,\n",
    "    iterations=50,\n",
    "    c_puct=1.41,\n",
    "    rollout_depth=10,\n",
    "    gamma=0.99,\n",
    ")\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    root = PUCTNode(state, env.score)\n",
    "    for _ in range(mcts_puct.iterations):\n",
    "        mcts_puct.run_simulation(root)\n",
    "\n",
    "    best_act, visit_distribution = mcts_puct.best_action_distribution(root)\n",
    "    print(\n",
    "        \"PUCT selected action:\",\n",
    "        best_act,\n",
    "        \"with visit distribution:\",\n",
    "        visit_distribution,\n",
    "    )\n",
    "\n",
    "    state, reward, done, _ = env.step(best_act)\n",
    "    env.render(action=best_act)\n",
    "\n",
    "\n",
    "# Print final results\n",
    "max_tile = np.max(state)  # Get the highest tile achieved\n",
    "print(f\"Game over! Final score: {env.score}, Highest tile: {max_tile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9M5mPKud8HkH"
   },
   "source": [
    "üí° Tip: Make the most of these two questions (Q1 & Q2) to understand key techniques‚Äîthey can be directly applied to Q3 to maximize your score! Keep pushing forward, and aim for the best results! üí™üî•\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
